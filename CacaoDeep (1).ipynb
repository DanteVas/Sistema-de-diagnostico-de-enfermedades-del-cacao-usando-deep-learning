{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eqTT2Qaj2OoG",
        "outputId": "01a1cc2c-b776-4281-9638-85af2d2aa2ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit\n",
            "  Downloading streamlit-1.46.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pdfkit\n",
            "  Downloading pdfkit-1.0.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.46.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfkit-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pdfkit, watchdog, pydeck, streamlit\n",
            "Successfully installed pdfkit-1.0.0 pydeck-0.9.1 streamlit-1.46.1 watchdog-6.0.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  avahi-daemon geoclue-2.0 glib-networking glib-networking-common\n",
            "  glib-networking-services gsettings-desktop-schemas iio-sensor-proxy\n",
            "  libavahi-core7 libavahi-glib1 libdaemon0 libevdev2 libgudev-1.0-0 libhyphen0\n",
            "  libinput-bin libinput10 libjson-glib-1.0-0 libjson-glib-1.0-common\n",
            "  libmbim-glib4 libmbim-proxy libmd4c0 libmm-glib0 libmtdev1 libnl-genl-3-200\n",
            "  libnotify4 libnss-mdns libproxy1v5 libqmi-glib5 libqmi-proxy libqt5core5a\n",
            "  libqt5dbus5 libqt5gui5 libqt5network5 libqt5positioning5 libqt5printsupport5\n",
            "  libqt5qml5 libqt5qmlmodels5 libqt5quick5 libqt5sensors5 libqt5svg5\n",
            "  libqt5webchannel5 libqt5webkit5 libqt5widgets5 libsoup2.4-1\n",
            "  libsoup2.4-common libudev1 libwacom-bin libwacom-common libwacom9 libwoff1\n",
            "  libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0 modemmanager\n",
            "  qt5-gtk-platformtheme qttranslations5-l10n session-migration\n",
            "  systemd-hwe-hwdb udev usb-modeswitch usb-modeswitch-data wpasupplicant\n",
            "Suggested packages:\n",
            "  avahi-autoipd gnome-shell | notification-daemon avahi-autoipd | zeroconf\n",
            "  qt5-image-formats-plugins qtwayland5 qt5-qmltooling-plugins comgt wvdial\n",
            "  wpagui libengine-pkcs11-openssl\n",
            "The following NEW packages will be installed:\n",
            "  avahi-daemon geoclue-2.0 glib-networking glib-networking-common\n",
            "  glib-networking-services gsettings-desktop-schemas iio-sensor-proxy\n",
            "  libavahi-core7 libavahi-glib1 libdaemon0 libevdev2 libgudev-1.0-0 libhyphen0\n",
            "  libinput-bin libinput10 libjson-glib-1.0-0 libjson-glib-1.0-common\n",
            "  libmbim-glib4 libmbim-proxy libmd4c0 libmm-glib0 libmtdev1 libnl-genl-3-200\n",
            "  libnotify4 libnss-mdns libproxy1v5 libqmi-glib5 libqmi-proxy libqt5core5a\n",
            "  libqt5dbus5 libqt5gui5 libqt5network5 libqt5positioning5 libqt5printsupport5\n",
            "  libqt5qml5 libqt5qmlmodels5 libqt5quick5 libqt5sensors5 libqt5svg5\n",
            "  libqt5webchannel5 libqt5webkit5 libqt5widgets5 libsoup2.4-1\n",
            "  libsoup2.4-common libwacom-bin libwacom-common libwacom9 libwoff1\n",
            "  libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0 modemmanager\n",
            "  qt5-gtk-platformtheme qttranslations5-l10n session-migration\n",
            "  systemd-hwe-hwdb udev usb-modeswitch usb-modeswitch-data wkhtmltopdf\n",
            "  wpasupplicant\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 67 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 35.5 MB of archives.\n",
            "After this operation, 141 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libavahi-core7 amd64 0.8-5ubuntu5.2 [90.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdaemon0 amd64 0.14-7.1ubuntu3 [14.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 avahi-daemon amd64 0.8-5ubuntu5.2 [69.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5core5a amd64 5.15.3+dfsg-2ubuntu0.2 [2,006 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevdev2 amd64 1.12.1+dfsg-1 [39.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmtdev1 amd64 1.1.6-1build4 [14.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.16 [76.7 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgudev-1.0-0 amd64 1:237-2build1 [16.3 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-common all 2.2.0-1 [54.3 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom9 amd64 2.2.0-1 [22.0 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput-bin amd64 1.20.0-1ubuntu0.3 [19.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput10 amd64 1.20.0-1ubuntu0.3 [131 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmd4c0 amd64 0.4.8-1 [42.0 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5dbus5 amd64 5.15.3+dfsg-2ubuntu0.2 [222 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5network5 amd64 5.15.3+dfsg-2ubuntu0.2 [731 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5gui5 amd64 5.15.3+dfsg-2ubuntu0.2 [3,722 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5widgets5 amd64 5.15.3+dfsg-2ubuntu0.2 [2,561 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5svg5 amd64 5.15.3-1 [149 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhyphen0 amd64 2.8.8-7build2 [28.2 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5positioning5 amd64 5.15.3+dfsg-3 [223 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5printsupport5 amd64 5.15.3+dfsg-2ubuntu0.2 [214 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5qml5 amd64 5.15.3+dfsg-1 [1,472 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5qmlmodels5 amd64 5.15.3+dfsg-1 [205 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5quick5 amd64 5.15.3+dfsg-1 [1,748 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5sensors5 amd64 5.15.3-1 [123 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5webchannel5 amd64 5.15.3-1 [62.9 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5webkit5 amd64 5.212.0~alpha4-15ubuntu1 [12.8 MB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.16 [1,557 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libavahi-glib1 amd64 0.8-5ubuntu5.2 [8,296 B]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-common all 1.6.6-1build1 [4,432 B]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-0 amd64 1.6.6-1build1 [69.9 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmm-glib0 amd64 1.20.0-1~ubuntu22.04.4 [262 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnotify4 amd64 0.7.9-3ubuntu5.22.04.1 [20.3 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/main amd64 libproxy1v5 amd64 0.4.17-2 [51.9 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-common all 2.72.0-1 [3,718 B]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-services amd64 2.72.0-1 [9,982 B]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking amd64 2.72.0-1 [69.8 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-common all 2.74.2-3ubuntu0.5 [4,660 B]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-1 amd64 2.74.2-3ubuntu0.5 [287 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/main amd64 geoclue-2.0 amd64 2.5.7-3ubuntu3 [111 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/main amd64 iio-sensor-proxy amd64 3.3-0ubuntu6 [34.4 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmbim-glib4 amd64 1.28.0-1~ubuntu20.04.2 [192 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmbim-proxy amd64 1.28.0-1~ubuntu20.04.2 [6,160 B]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnss-mdns amd64 0.15.1-1ubuntu1 [27.0 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libqmi-glib5 amd64 1.32.0-1ubuntu0.22.04.1 [772 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libqmi-proxy amd64 1.32.0-1ubuntu0.22.04.1 [6,072 B]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-bin amd64 2.2.0-1 [13.6 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 modemmanager amd64 1.20.0-1~ubuntu22.04.4 [1,094 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 qt5-gtk-platformtheme amd64 5.15.3+dfsg-2ubuntu0.2 [130 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qttranslations5-l10n all 5.15.3-1 [1,983 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 wpasupplicant amd64 2:2.10-6ubuntu2.2 [1,482 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb-modeswitch-data all 20191128-4 [33.2 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb-modeswitch amd64 2.6.1-3ubuntu2 [46.0 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu jammy/universe amd64 wkhtmltopdf amd64 0.12.6-2 [173 kB]\n",
            "Fetched 35.5 MB in 1s (42.3 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package libavahi-core7:amd64.\n",
            "(Reading database ... 126281 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libavahi-core7_0.8-5ubuntu5.2_amd64.deb ...\n",
            "Unpacking libavahi-core7:amd64 (0.8-5ubuntu5.2) ...\n",
            "Selecting previously unselected package libdaemon0:amd64.\n",
            "Preparing to unpack .../1-libdaemon0_0.14-7.1ubuntu3_amd64.deb ...\n",
            "Unpacking libdaemon0:amd64 (0.14-7.1ubuntu3) ...\n",
            "Selecting previously unselected package avahi-daemon.\n",
            "Preparing to unpack .../2-avahi-daemon_0.8-5ubuntu5.2_amd64.deb ...\n",
            "Unpacking avahi-daemon (0.8-5ubuntu5.2) ...\n",
            "Selecting previously unselected package libqt5core5a:amd64.\n",
            "Preparing to unpack .../3-libqt5core5a_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libevdev2:amd64.\n",
            "Preparing to unpack .../4-libevdev2_1.12.1+dfsg-1_amd64.deb ...\n",
            "Unpacking libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Selecting previously unselected package libmtdev1:amd64.\n",
            "Preparing to unpack .../5-libmtdev1_1.1.6-1build4_amd64.deb ...\n",
            "Unpacking libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Preparing to unpack .../6-libudev1_249.11-0ubuntu3.16_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.16) ...\n",
            "Selecting previously unselected package libgudev-1.0-0:amd64.\n",
            "(Reading database ... 126350 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\n",
            "Unpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Selecting previously unselected package libwacom-common.\n",
            "Preparing to unpack .../01-libwacom-common_2.2.0-1_all.deb ...\n",
            "Unpacking libwacom-common (2.2.0-1) ...\n",
            "Selecting previously unselected package libwacom9:amd64.\n",
            "Preparing to unpack .../02-libwacom9_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom9:amd64 (2.2.0-1) ...\n",
            "Selecting previously unselected package libinput-bin.\n",
            "Preparing to unpack .../03-libinput-bin_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libinput10:amd64.\n",
            "Preparing to unpack .../04-libinput10_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libmd4c0:amd64.\n",
            "Preparing to unpack .../05-libmd4c0_0.4.8-1_amd64.deb ...\n",
            "Unpacking libmd4c0:amd64 (0.4.8-1) ...\n",
            "Selecting previously unselected package libqt5dbus5:amd64.\n",
            "Preparing to unpack .../06-libqt5dbus5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5network5:amd64.\n",
            "Preparing to unpack .../07-libqt5network5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libxcb-icccm4:amd64.\n",
            "Preparing to unpack .../08-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
            "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Selecting previously unselected package libxcb-util1:amd64.\n",
            "Preparing to unpack .../09-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
            "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Selecting previously unselected package libxcb-image0:amd64.\n",
            "Preparing to unpack .../10-libxcb-image0_0.4.0-2_amd64.deb ...\n",
            "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
            "Preparing to unpack .../11-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
            "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Selecting previously unselected package libxcb-render-util0:amd64.\n",
            "Preparing to unpack .../12-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
            "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
            "Preparing to unpack .../13-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xinput0:amd64.\n",
            "Preparing to unpack .../14-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xkb1:amd64.\n",
            "Preparing to unpack .../15-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxkbcommon-x11-0:amd64.\n",
            "Preparing to unpack .../16-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libqt5gui5:amd64.\n",
            "Preparing to unpack .../17-libqt5gui5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5widgets5:amd64.\n",
            "Preparing to unpack .../18-libqt5widgets5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5svg5:amd64.\n",
            "Preparing to unpack .../19-libqt5svg5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libhyphen0:amd64.\n",
            "Preparing to unpack .../20-libhyphen0_2.8.8-7build2_amd64.deb ...\n",
            "Unpacking libhyphen0:amd64 (2.8.8-7build2) ...\n",
            "Selecting previously unselected package libqt5positioning5:amd64.\n",
            "Preparing to unpack .../21-libqt5positioning5_5.15.3+dfsg-3_amd64.deb ...\n",
            "Unpacking libqt5positioning5:amd64 (5.15.3+dfsg-3) ...\n",
            "Selecting previously unselected package libqt5printsupport5:amd64.\n",
            "Preparing to unpack .../22-libqt5printsupport5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5qml5:amd64.\n",
            "Preparing to unpack .../23-libqt5qml5_5.15.3+dfsg-1_amd64.deb ...\n",
            "Unpacking libqt5qml5:amd64 (5.15.3+dfsg-1) ...\n",
            "Selecting previously unselected package libqt5qmlmodels5:amd64.\n",
            "Preparing to unpack .../24-libqt5qmlmodels5_5.15.3+dfsg-1_amd64.deb ...\n",
            "Unpacking libqt5qmlmodels5:amd64 (5.15.3+dfsg-1) ...\n",
            "Selecting previously unselected package libqt5quick5:amd64.\n",
            "Preparing to unpack .../25-libqt5quick5_5.15.3+dfsg-1_amd64.deb ...\n",
            "Unpacking libqt5quick5:amd64 (5.15.3+dfsg-1) ...\n",
            "Selecting previously unselected package libqt5sensors5:amd64.\n",
            "Preparing to unpack .../26-libqt5sensors5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5sensors5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libqt5webchannel5:amd64.\n",
            "Preparing to unpack .../27-libqt5webchannel5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5webchannel5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libwoff1:amd64.\n",
            "Preparing to unpack .../28-libwoff1_1.0.2-1build4_amd64.deb ...\n",
            "Unpacking libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Selecting previously unselected package libqt5webkit5:amd64.\n",
            "Preparing to unpack .../29-libqt5webkit5_5.212.0~alpha4-15ubuntu1_amd64.deb ...\n",
            "Unpacking libqt5webkit5:amd64 (5.212.0~alpha4-15ubuntu1) ...\n",
            "Selecting previously unselected package udev.\n",
            "Preparing to unpack .../30-udev_249.11-0ubuntu3.16_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.16) ...\n",
            "Selecting previously unselected package libavahi-glib1:amd64.\n",
            "Preparing to unpack .../31-libavahi-glib1_0.8-5ubuntu5.2_amd64.deb ...\n",
            "Unpacking libavahi-glib1:amd64 (0.8-5ubuntu5.2) ...\n",
            "Selecting previously unselected package libjson-glib-1.0-common.\n",
            "Preparing to unpack .../32-libjson-glib-1.0-common_1.6.6-1build1_all.deb ...\n",
            "Unpacking libjson-glib-1.0-common (1.6.6-1build1) ...\n",
            "Selecting previously unselected package libjson-glib-1.0-0:amd64.\n",
            "Preparing to unpack .../33-libjson-glib-1.0-0_1.6.6-1build1_amd64.deb ...\n",
            "Unpacking libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\n",
            "Selecting previously unselected package libmm-glib0:amd64.\n",
            "Preparing to unpack .../34-libmm-glib0_1.20.0-1~ubuntu22.04.4_amd64.deb ...\n",
            "Unpacking libmm-glib0:amd64 (1.20.0-1~ubuntu22.04.4) ...\n",
            "Selecting previously unselected package libnotify4:amd64.\n",
            "Preparing to unpack .../35-libnotify4_0.7.9-3ubuntu5.22.04.1_amd64.deb ...\n",
            "Unpacking libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Selecting previously unselected package libproxy1v5:amd64.\n",
            "Preparing to unpack .../36-libproxy1v5_0.4.17-2_amd64.deb ...\n",
            "Unpacking libproxy1v5:amd64 (0.4.17-2) ...\n",
            "Selecting previously unselected package glib-networking-common.\n",
            "Preparing to unpack .../37-glib-networking-common_2.72.0-1_all.deb ...\n",
            "Unpacking glib-networking-common (2.72.0-1) ...\n",
            "Selecting previously unselected package glib-networking-services.\n",
            "Preparing to unpack .../38-glib-networking-services_2.72.0-1_amd64.deb ...\n",
            "Unpacking glib-networking-services (2.72.0-1) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../39-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../40-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package glib-networking:amd64.\n",
            "Preparing to unpack .../41-glib-networking_2.72.0-1_amd64.deb ...\n",
            "Unpacking glib-networking:amd64 (2.72.0-1) ...\n",
            "Selecting previously unselected package libsoup2.4-common.\n",
            "Preparing to unpack .../42-libsoup2.4-common_2.74.2-3ubuntu0.5_all.deb ...\n",
            "Unpacking libsoup2.4-common (2.74.2-3ubuntu0.5) ...\n",
            "Selecting previously unselected package libsoup2.4-1:amd64.\n",
            "Preparing to unpack .../43-libsoup2.4-1_2.74.2-3ubuntu0.5_amd64.deb ...\n",
            "Unpacking libsoup2.4-1:amd64 (2.74.2-3ubuntu0.5) ...\n",
            "Selecting previously unselected package geoclue-2.0.\n",
            "Preparing to unpack .../44-geoclue-2.0_2.5.7-3ubuntu3_amd64.deb ...\n",
            "Unpacking geoclue-2.0 (2.5.7-3ubuntu3) ...\n",
            "Selecting previously unselected package iio-sensor-proxy.\n",
            "Preparing to unpack .../45-iio-sensor-proxy_3.3-0ubuntu6_amd64.deb ...\n",
            "Unpacking iio-sensor-proxy (3.3-0ubuntu6) ...\n",
            "Selecting previously unselected package libmbim-glib4:amd64.\n",
            "Preparing to unpack .../46-libmbim-glib4_1.28.0-1~ubuntu20.04.2_amd64.deb ...\n",
            "Unpacking libmbim-glib4:amd64 (1.28.0-1~ubuntu20.04.2) ...\n",
            "Selecting previously unselected package libmbim-proxy.\n",
            "Preparing to unpack .../47-libmbim-proxy_1.28.0-1~ubuntu20.04.2_amd64.deb ...\n",
            "Unpacking libmbim-proxy (1.28.0-1~ubuntu20.04.2) ...\n",
            "Selecting previously unselected package libnl-genl-3-200:amd64.\n",
            "Preparing to unpack .../48-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...\n",
            "Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...\n",
            "Selecting previously unselected package libnss-mdns:amd64.\n",
            "Preparing to unpack .../49-libnss-mdns_0.15.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnss-mdns:amd64 (0.15.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libqmi-glib5:amd64.\n",
            "Preparing to unpack .../50-libqmi-glib5_1.32.0-1ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libqmi-glib5:amd64 (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libqmi-proxy.\n",
            "Preparing to unpack .../51-libqmi-proxy_1.32.0-1ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libqmi-proxy (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libwacom-bin.\n",
            "Preparing to unpack .../52-libwacom-bin_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom-bin (2.2.0-1) ...\n",
            "Selecting previously unselected package modemmanager.\n",
            "Preparing to unpack .../53-modemmanager_1.20.0-1~ubuntu22.04.4_amd64.deb ...\n",
            "Unpacking modemmanager (1.20.0-1~ubuntu22.04.4) ...\n",
            "Selecting previously unselected package qt5-gtk-platformtheme:amd64.\n",
            "Preparing to unpack .../54-qt5-gtk-platformtheme_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package qttranslations5-l10n.\n",
            "Preparing to unpack .../55-qttranslations5-l10n_5.15.3-1_all.deb ...\n",
            "Unpacking qttranslations5-l10n (5.15.3-1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../56-systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Selecting previously unselected package wpasupplicant.\n",
            "Preparing to unpack .../57-wpasupplicant_2%3a2.10-6ubuntu2.2_amd64.deb ...\n",
            "Unpacking wpasupplicant (2:2.10-6ubuntu2.2) ...\n",
            "Selecting previously unselected package usb-modeswitch-data.\n",
            "Preparing to unpack .../58-usb-modeswitch-data_20191128-4_all.deb ...\n",
            "Unpacking usb-modeswitch-data (20191128-4) ...\n",
            "Selecting previously unselected package usb-modeswitch.\n",
            "Preparing to unpack .../59-usb-modeswitch_2.6.1-3ubuntu2_amd64.deb ...\n",
            "Unpacking usb-modeswitch (2.6.1-3ubuntu2) ...\n",
            "Selecting previously unselected package wkhtmltopdf.\n",
            "Preparing to unpack .../60-wkhtmltopdf_0.12.6-2_amd64.deb ...\n",
            "Unpacking wkhtmltopdf (0.12.6-2) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service → /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libproxy1v5:amd64 (0.4.17-2) ...\n",
            "Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Setting up libhyphen0:amd64 (2.8.8-7build2) ...\n",
            "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up qttranslations5-l10n (5.15.3-1) ...\n",
            "Setting up libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Setting up usb-modeswitch-data (20191128-4) ...\n",
            "Setting up udev (249.11-0ubuntu3.16) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Setting up libsoup2.4-common (2.74.2-3ubuntu0.5) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up libmm-glib0:amd64 (1.20.0-1~ubuntu22.04.4) ...\n",
            "Setting up libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...\n",
            "Setting up libmd4c0:amd64 (0.4.8-1) ...\n",
            "Setting up libavahi-glib1:amd64 (0.8-5ubuntu5.2) ...\n",
            "Setting up libjson-glib-1.0-common (1.6.6-1build1) ...\n",
            "Setting up usb-modeswitch (2.6.1-3ubuntu2) ...\n",
            "Setting up glib-networking-common (2.72.0-1) ...\n",
            "Setting up libqt5sensors5:amd64 (5.15.3-1) ...\n",
            "Setting up libdaemon0:amd64 (0.14-7.1ubuntu3) ...\n",
            "Setting up libavahi-core7:amd64 (0.8-5ubuntu5.2) ...\n",
            "Setting up libnss-mdns:amd64 (0.15.1-1ubuntu1) ...\n",
            "First installation detected...\n",
            "Checking NSS setup...\n",
            "Setting up libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Setting up libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Setting up libmbim-glib4:amd64 (1.28.0-1~ubuntu20.04.2) ...\n",
            "Setting up libwacom-common (2.2.0-1) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up glib-networking-services (2.72.0-1) ...\n",
            "Setting up iio-sensor-proxy (3.3-0ubuntu6) ...\n",
            "Setting up libwacom9:amd64 (2.2.0-1) ...\n",
            "Setting up libqt5positioning5:amd64 (5.15.3+dfsg-3) ...\n",
            "Setting up libmbim-proxy (1.28.0-1~ubuntu20.04.2) ...\n",
            "Setting up libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\n",
            "Setting up libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Setting up wpasupplicant (2:2.10-6ubuntu2.2) ...\n",
            "Created symlink /etc/systemd/system/dbus-fi.w1.wpa_supplicant1.service → /lib/systemd/system/wpa_supplicant.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/wpa_supplicant.service → /lib/systemd/system/wpa_supplicant.service.\n",
            "Setting up libqt5qml5:amd64 (5.15.3+dfsg-1) ...\n",
            "Setting up libqt5webchannel5:amd64 (5.15.3-1) ...\n",
            "Setting up libwacom-bin (2.2.0-1) ...\n",
            "Setting up avahi-daemon (0.8-5ubuntu5.2) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of force-reload.\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Created symlink /etc/systemd/system/dbus-org.freedesktop.Avahi.service → /lib/systemd/system/avahi-daemon.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/avahi-daemon.service → /lib/systemd/system/avahi-daemon.service.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/avahi-daemon.socket → /lib/systemd/system/avahi-daemon.socket.\n",
            "Setting up libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Setting up libqt5qmlmodels5:amd64 (5.15.3+dfsg-1) ...\n",
            "Setting up libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqmi-glib5:amd64 (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Setting up libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5quick5:amd64 (5.15.3+dfsg-1) ...\n",
            "Setting up libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Setting up libqmi-proxy (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Setting up libqt5webkit5:amd64 (5.212.0~alpha4-15ubuntu1) ...\n",
            "Setting up modemmanager (1.20.0-1~ubuntu22.04.4) ...\n",
            "Created symlink /etc/systemd/system/dbus-org.freedesktop.ModemManager1.service → /lib/systemd/system/ModemManager.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/ModemManager.service → /lib/systemd/system/ModemManager.service.\n",
            "Setting up wkhtmltopdf (0.12.6-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Setting up glib-networking:amd64 (2.72.0-1) ...\n",
            "Setting up libsoup2.4-1:amd64 (2.74.2-3ubuntu0.5) ...\n",
            "Setting up geoclue-2.0 (2.5.7-3ubuntu3) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n"
          ]
        }
      ],
      "source": [
        "# Instala librerías requeridas\n",
        "!pip install tensorflow scikit-learn matplotlib seaborn statsmodels kaggle opencv-python-headless tf-keras-vis --quiet\n",
        "!pip install streamlit pdfkit\n",
        "!apt-get install -y wkhtmltopdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "collapsed": true,
        "id": "63RDdG_w2abP",
        "outputId": "1fbd9d5c-ec8e-47a9-9885-60e57ab90f1d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2c564cff-bcf6-456f-83b9-a0cf2aec262e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2c564cff-bcf6-456f-83b9-a0cf2aec262e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Subir kaggle.json\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sdrOYm92u1J",
        "outputId": "dae94ce1-9c1e-44e3-f2e3-c55a866c28c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/zaldyjr/cacao-diseases\n",
            "License(s): CC-BY-SA-4.0\n",
            "Downloading cacao-diseases.zip to /content\n",
            " 99% 1.01G/1.01G [00:04<00:00, 186MB/s]\n",
            "100% 1.01G/1.01G [00:05<00:00, 217MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Descarga el dataset\n",
        "!kaggle datasets download -d zaldyjr/cacao-diseases\n",
        "!unzip -q cacao-diseases.zip -d cacao_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POfpbi_U2zhD",
        "outputId": "23fc2508-f7d6-4edd-c33e-c9ddcd1a213f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clases encontradas: ['healthy', 'black_pod_rot', 'pod_borer']\n",
            "healthy: 3344 imágenes\n",
            "black_pod_rot: 943 imágenes\n",
            "pod_borer: 103 imágenes\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "base_dir = 'cacao_data/cacao_diseases/cacao_photos'\n",
        "clases = os.listdir(base_dir)\n",
        "print(\"Clases encontradas:\", clases)\n",
        "for clase in clases:\n",
        "    ruta = os.path.join(base_dir, clase)\n",
        "    print(f\"{clase}: {len(os.listdir(ruta))} imágenes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-dS2wBw2-hf",
        "outputId": "dd27e32b-58ec-41d2-951e-a1f8cbbbac86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: label\n",
            "pod_borer        72\n",
            "black_pod_rot    72\n",
            "healthy          72\n",
            "Name: count, dtype: int64\n",
            "Val: label\n",
            "pod_borer        15\n",
            "black_pod_rot    15\n",
            "healthy          15\n",
            "Name: count, dtype: int64\n",
            "Test: label\n",
            "black_pod_rot    16\n",
            "pod_borer        16\n",
            "healthy          16\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "base_dir = 'cacao_data/cacao_diseases/cacao_photos'\n",
        "clases = ['healthy', 'black_pod_rot', 'pod_borer']\n",
        "imgs_per_class = 103\n",
        "\n",
        "# Recolectar imágenes balanceadas\n",
        "data = []\n",
        "for clase in clases:\n",
        "    ruta = os.path.join(base_dir, clase)\n",
        "    imgs = os.listdir(ruta)\n",
        "    # Filtrar solo archivos de imagen válidos\n",
        "    imgs = [img for img in imgs if img.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    # Asegurarse de que hay suficientes imágenes para seleccionar\n",
        "    if len(imgs) < imgs_per_class:\n",
        "        print(f\"Advertencia: La clase '{clase}' tiene menos de {imgs_per_class} imágenes. Usando todas las disponibles.\")\n",
        "        selected_imgs = imgs\n",
        "    else:\n",
        "        selected_imgs = random.sample(imgs, imgs_per_class)\n",
        "    for img in selected_imgs:\n",
        "        data.append({'filepath': os.path.join(ruta, img), 'label': clase})\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)  # Mezclar\n",
        "\n",
        "# Codificar etiquetas numéricas\n",
        "label_dict = {clase: idx for idx, clase in enumerate(clases)}\n",
        "df['label_num'] = df['label'].map(label_dict)\n",
        "\n",
        "# Separar por clase\n",
        "df_train, df_val, df_test = [], [], []\n",
        "# Calcular el número de imágenes por conjunto para cada clase\n",
        "# Asumiendo 103 imágenes por clase:\n",
        "# 70% para entrenamiento (~72 imágenes)\n",
        "# 15% para validación (~15 imágenes)\n",
        "# 15% para prueba (~16 imágenes)\n",
        "train_count = int(imgs_per_class * 0.70)\n",
        "val_count = int(imgs_per_class * 0.15)\n",
        "test_count = imgs_per_class - train_count - val_count # El resto para asegurar 103\n",
        "\n",
        "for clase in clases:\n",
        "    dft = df[df['label'] == clase]\n",
        "    train = dft.iloc[:train_count]\n",
        "    val = dft.iloc[train_count : train_count + val_count]\n",
        "    test = dft.iloc[train_count + val_count : train_count + val_count + test_count] # Asegurar que no exceda el límite\n",
        "\n",
        "    df_train.append(train)\n",
        "    df_val.append(val)\n",
        "    df_test.append(test)\n",
        "\n",
        "df_train = pd.concat(df_train).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df_val = pd.concat(df_val).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df_test = pd.concat(df_test).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(\"Train:\", df_train['label'].value_counts())\n",
        "print(\"Val:\", df_val['label'].value_counts())\n",
        "print(\"Test:\", df_test['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "IMG_SIZE = (128, 128)\n",
        "\n",
        "def load_images(df):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i, row in df.iterrows():\n",
        "        img = Image.open(row['filepath']).convert('RGB').resize(IMG_SIZE)\n",
        "        X.append(np.array(img)/255.0)\n",
        "        y.append(row['label_num'])\n",
        "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int32)\n",
        "\n",
        "X_train, y_train = load_images(df_train)\n",
        "X_val, y_val = load_images(df_val)\n",
        "X_test, y_test = load_images(df_test)\n",
        "\n",
        "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_val:\", X_val.shape, \"y_val:\", y_val.shape)\n",
        "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Nttm6kQ-3G5Q",
        "outputId": "c95111f1-84fb-4a85-a73b-0377bd5e3b9a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (216, 128, 128, 3) y_train: (216,)\n",
            "X_val: (45, 128, 128, 3) y_val: (45,)\n",
            "X_test: (48, 128, 128, 3) y_test: (48,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "_1S1lWI93DDZ",
        "outputId": "86b63f66-0d5d-4601-e73e-f14872b6056e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-10-4223691561.py, line 27)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-10-4223691561.py\"\u001b[0;36m, line \u001b[0;32m27\u001b[0m\n\u001b[0;31m    X_train, y_train = load_images(df_train)import tensorflow as tf\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2 # Importar OpenCV para preprocesamiento avanzado\n",
        "\n",
        "IMG_SIZE = (128, 128)\n",
        "\n",
        "def load_images(df):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i, row in df.iterrows():\n",
        "        img = Image.open(row['filepath']).convert('RGB')\n",
        "        img = np.array(img)\n",
        "\n",
        "        # Aplicar preprocesamiento avanzado (CLAHE)\n",
        "        img = cv2.resize(img, IMG_SIZE)\n",
        "        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "        cl = clahe.apply(l)\n",
        "        limg = cv2.merge((cl, a, b))\n",
        "        img = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "        X.append(img / 255.0) # Normalizar\n",
        "        y.append(row['label_num'])\n",
        "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int32)\n",
        "\n",
        "X_train, y_train = load_images(df_train)import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, applications\n",
        "\n",
        "input_shape = (128, 128, 3)\n",
        "num_classes = 3\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# Modelo 1: CNN sencilla\n",
        "def build_cnn_simple(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Modelo 2: CNN profunda\n",
        "def build_cnn_deep(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "        layers.Conv2D(32, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Modelo 3: MobileNetV2 Transfer Learning\n",
        "def build_mobilenet(input_shape, num_classes):\n",
        "    base = applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    base.trainable = False  # Congelar base\n",
        "    model = models.Sequential([\n",
        "        base,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Modelo 4: ResNet50 Transfer Learning\n",
        "def build_resnet50(input_shape, num_classes):\n",
        "    base = applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    base.trainable = False # Congelar base\n",
        "    model = models.Sequential([\n",
        "        base,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Suponiendo que ya tienes cargados tus datos X_train, y_train, X_val, y_val\n",
        "\n",
        "print(\"Entrenando CNN Simple...\")\n",
        "cnn_simple = build_cnn_simple(input_shape, num_classes)\n",
        "history1 = cnn_simple.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"\\nEntrenando CNN Profunda...\")\n",
        "cnn_deep = build_cnn_deep(input_shape, num_classes)\n",
        "history2 = cnn_deep.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"\\nEntrenando MobileNetV2...\")\n",
        "mobilenet = build_mobilenet(input_shape, num_classes)\n",
        "history3 = mobilenet.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"\\nEntrenando ResNet50...\")\n",
        "resnet50 = build_resnet50(input_shape, num_classes)\n",
        "history4 = resnet50.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Guardar modelos entrenados\n",
        "cnn_simple.save('cnn_simple.h5')\n",
        "cnn_deep.save('cnn_deep.h5')\n",
        "mobilenet.save('mobilenet.h5')\n",
        "resnet50.save('resnet50.h5')\n",
        "\n",
        "X_val, y_val = load_images(df_val)\n",
        "X_test, y_test = load_images(df_test)\n",
        "\n",
        "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_val:\", X_val.shape, \"y_val:\", y_val.shape)\n",
        "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t462qktn3H-D",
        "outputId": "b6b4865c-4c1e-4a5d-dc2f-cbb6438f3682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando CNN Simple...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "27/27 - 9s - 331ms/step - accuracy: 0.3241 - loss: 1.4844 - val_accuracy: 0.3333 - val_loss: 1.0981\n",
            "Epoch 2/30\n",
            "27/27 - 5s - 198ms/step - accuracy: 0.4074 - loss: 1.0910 - val_accuracy: 0.4667 - val_loss: 1.0377\n",
            "Epoch 3/30\n",
            "27/27 - 11s - 399ms/step - accuracy: 0.6111 - loss: 0.9100 - val_accuracy: 0.5111 - val_loss: 0.9620\n",
            "Epoch 4/30\n",
            "27/27 - 5s - 195ms/step - accuracy: 0.6713 - loss: 0.7426 - val_accuracy: 0.6444 - val_loss: 0.7561\n",
            "Epoch 5/30\n",
            "27/27 - 10s - 377ms/step - accuracy: 0.8056 - loss: 0.4668 - val_accuracy: 0.6889 - val_loss: 0.6795\n",
            "Epoch 6/30\n",
            "27/27 - 10s - 378ms/step - accuracy: 0.9120 - loss: 0.2462 - val_accuracy: 0.7556 - val_loss: 0.6018\n",
            "Epoch 7/30\n",
            "27/27 - 10s - 379ms/step - accuracy: 0.9815 - loss: 0.0967 - val_accuracy: 0.7778 - val_loss: 0.5936\n",
            "Epoch 8/30\n",
            "27/27 - 11s - 418ms/step - accuracy: 0.9907 - loss: 0.0338 - val_accuracy: 0.7333 - val_loss: 0.9193\n",
            "Epoch 9/30\n",
            "27/27 - 10s - 388ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.7333 - val_loss: 0.6809\n",
            "Epoch 10/30\n",
            "27/27 - 9s - 332ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.7333 - val_loss: 0.7881\n",
            "Epoch 11/30\n",
            "27/27 - 10s - 378ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.7556 - val_loss: 0.7508\n",
            "Epoch 12/30\n",
            "27/27 - 6s - 239ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7556 - val_loss: 0.7548\n",
            "Epoch 13/30\n",
            "27/27 - 9s - 347ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7111 - val_loss: 0.7918\n",
            "Epoch 14/30\n",
            "27/27 - 10s - 366ms/step - accuracy: 1.0000 - loss: 8.5746e-04 - val_accuracy: 0.7778 - val_loss: 0.7868\n",
            "Epoch 15/30\n",
            "27/27 - 10s - 379ms/step - accuracy: 1.0000 - loss: 7.3481e-04 - val_accuracy: 0.7778 - val_loss: 0.7984\n",
            "Epoch 16/30\n",
            "27/27 - 10s - 377ms/step - accuracy: 1.0000 - loss: 6.0465e-04 - val_accuracy: 0.7556 - val_loss: 0.8204\n",
            "Epoch 17/30\n",
            "27/27 - 6s - 223ms/step - accuracy: 1.0000 - loss: 5.1997e-04 - val_accuracy: 0.7556 - val_loss: 0.8382\n",
            "Epoch 18/30\n",
            "27/27 - 9s - 346ms/step - accuracy: 1.0000 - loss: 4.5108e-04 - val_accuracy: 0.7556 - val_loss: 0.8624\n",
            "Epoch 19/30\n",
            "27/27 - 7s - 241ms/step - accuracy: 1.0000 - loss: 3.8313e-04 - val_accuracy: 0.7556 - val_loss: 0.8874\n",
            "Epoch 20/30\n",
            "27/27 - 10s - 358ms/step - accuracy: 1.0000 - loss: 3.2402e-04 - val_accuracy: 0.7556 - val_loss: 0.8989\n",
            "Epoch 21/30\n",
            "27/27 - 9s - 351ms/step - accuracy: 1.0000 - loss: 2.7822e-04 - val_accuracy: 0.7333 - val_loss: 0.9419\n",
            "Epoch 22/30\n",
            "27/27 - 10s - 378ms/step - accuracy: 1.0000 - loss: 2.5011e-04 - val_accuracy: 0.7556 - val_loss: 0.9335\n",
            "Epoch 23/30\n",
            "27/27 - 10s - 380ms/step - accuracy: 1.0000 - loss: 2.1196e-04 - val_accuracy: 0.7333 - val_loss: 0.9605\n",
            "Epoch 24/30\n",
            "27/27 - 11s - 393ms/step - accuracy: 1.0000 - loss: 1.8798e-04 - val_accuracy: 0.7111 - val_loss: 0.9551\n",
            "Epoch 25/30\n",
            "27/27 - 11s - 411ms/step - accuracy: 1.0000 - loss: 1.6036e-04 - val_accuracy: 0.7333 - val_loss: 0.9756\n",
            "Epoch 26/30\n",
            "27/27 - 5s - 194ms/step - accuracy: 1.0000 - loss: 1.3675e-04 - val_accuracy: 0.7111 - val_loss: 0.9897\n",
            "Epoch 27/30\n",
            "27/27 - 10s - 378ms/step - accuracy: 1.0000 - loss: 1.2161e-04 - val_accuracy: 0.7333 - val_loss: 0.9930\n",
            "Epoch 28/30\n",
            "27/27 - 11s - 392ms/step - accuracy: 1.0000 - loss: 1.0541e-04 - val_accuracy: 0.7111 - val_loss: 1.0242\n",
            "Epoch 29/30\n",
            "27/27 - 11s - 415ms/step - accuracy: 1.0000 - loss: 9.5285e-05 - val_accuracy: 0.7556 - val_loss: 1.0373\n",
            "Epoch 30/30\n",
            "27/27 - 5s - 193ms/step - accuracy: 1.0000 - loss: 8.2441e-05 - val_accuracy: 0.7333 - val_loss: 1.0537\n",
            "\n",
            "Entrenando CNN Profunda...\n",
            "Epoch 1/30\n",
            "27/27 - 20s - 736ms/step - accuracy: 0.3009 - loss: 1.1192 - val_accuracy: 0.3333 - val_loss: 1.0981\n",
            "Epoch 2/30\n",
            "27/27 - 19s - 692ms/step - accuracy: 0.3333 - loss: 1.0954 - val_accuracy: 0.3333 - val_loss: 1.0623\n",
            "Epoch 3/30\n",
            "27/27 - 20s - 724ms/step - accuracy: 0.5787 - loss: 0.9525 - val_accuracy: 0.3556 - val_loss: 1.0162\n",
            "Epoch 4/30\n",
            "27/27 - 22s - 805ms/step - accuracy: 0.5972 - loss: 0.8635 - val_accuracy: 0.5111 - val_loss: 0.9609\n",
            "Epoch 5/30\n",
            "27/27 - 17s - 636ms/step - accuracy: 0.6991 - loss: 0.7489 - val_accuracy: 0.6000 - val_loss: 0.7747\n",
            "Epoch 6/30\n",
            "27/27 - 23s - 853ms/step - accuracy: 0.6991 - loss: 0.6674 - val_accuracy: 0.6667 - val_loss: 0.7078\n",
            "Epoch 7/30\n",
            "27/27 - 18s - 678ms/step - accuracy: 0.7639 - loss: 0.5097 - val_accuracy: 0.7333 - val_loss: 0.7770\n",
            "Epoch 8/30\n",
            "27/27 - 22s - 805ms/step - accuracy: 0.8287 - loss: 0.3960 - val_accuracy: 0.6889 - val_loss: 0.7194\n",
            "Epoch 9/30\n",
            "27/27 - 19s - 712ms/step - accuracy: 0.8981 - loss: 0.2669 - val_accuracy: 0.7111 - val_loss: 0.8487\n",
            "Epoch 10/30\n",
            "27/27 - 22s - 800ms/step - accuracy: 0.8380 - loss: 0.4543 - val_accuracy: 0.7111 - val_loss: 0.8687\n",
            "Epoch 11/30\n",
            "27/27 - 25s - 910ms/step - accuracy: 0.8935 - loss: 0.2985 - val_accuracy: 0.5778 - val_loss: 0.8648\n",
            "Epoch 12/30\n",
            "27/27 - 41s - 2s/step - accuracy: 0.8981 - loss: 0.2392 - val_accuracy: 0.6889 - val_loss: 1.0504\n",
            "Epoch 13/30\n",
            "27/27 - 37s - 1s/step - accuracy: 0.9722 - loss: 0.0945 - val_accuracy: 0.6889 - val_loss: 1.0798\n",
            "Epoch 14/30\n",
            "27/27 - 31s - 1s/step - accuracy: 0.9769 - loss: 0.0754 - val_accuracy: 0.6889 - val_loss: 1.2639\n",
            "Epoch 15/30\n",
            "27/27 - 29s - 1s/step - accuracy: 0.9491 - loss: 0.1483 - val_accuracy: 0.6444 - val_loss: 2.1062\n",
            "Epoch 16/30\n",
            "27/27 - 22s - 799ms/step - accuracy: 0.9398 - loss: 0.1541 - val_accuracy: 0.6667 - val_loss: 1.2099\n",
            "Epoch 17/30\n",
            "27/27 - 21s - 773ms/step - accuracy: 0.9583 - loss: 0.0919 - val_accuracy: 0.6222 - val_loss: 1.3840\n",
            "Epoch 18/30\n",
            "27/27 - 20s - 726ms/step - accuracy: 0.9815 - loss: 0.0451 - val_accuracy: 0.6444 - val_loss: 2.0946\n",
            "Epoch 19/30\n",
            "27/27 - 20s - 727ms/step - accuracy: 0.9954 - loss: 0.0256 - val_accuracy: 0.6889 - val_loss: 1.7419\n",
            "Epoch 20/30\n",
            "27/27 - 19s - 698ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.7111 - val_loss: 2.0452\n",
            "Epoch 21/30\n",
            "27/27 - 20s - 733ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.6667 - val_loss: 2.2565\n",
            "Epoch 22/30\n",
            "27/27 - 19s - 715ms/step - accuracy: 1.0000 - loss: 4.7640e-04 - val_accuracy: 0.7111 - val_loss: 2.3489\n",
            "Epoch 23/30\n",
            "27/27 - 19s - 695ms/step - accuracy: 1.0000 - loss: 2.8773e-04 - val_accuracy: 0.7111 - val_loss: 2.4130\n",
            "Epoch 24/30\n",
            "27/27 - 22s - 814ms/step - accuracy: 1.0000 - loss: 2.1023e-04 - val_accuracy: 0.7111 - val_loss: 2.4622\n",
            "Epoch 25/30\n",
            "27/27 - 19s - 709ms/step - accuracy: 1.0000 - loss: 1.6446e-04 - val_accuracy: 0.7111 - val_loss: 2.5027\n",
            "Epoch 26/30\n",
            "27/27 - 20s - 728ms/step - accuracy: 1.0000 - loss: 1.3320e-04 - val_accuracy: 0.7333 - val_loss: 2.5297\n",
            "Epoch 27/30\n",
            "27/27 - 19s - 702ms/step - accuracy: 1.0000 - loss: 1.0597e-04 - val_accuracy: 0.7111 - val_loss: 2.5633\n",
            "Epoch 28/30\n",
            "27/27 - 20s - 757ms/step - accuracy: 1.0000 - loss: 8.4180e-05 - val_accuracy: 0.7111 - val_loss: 2.5942\n",
            "Epoch 29/30\n",
            "27/27 - 20s - 745ms/step - accuracy: 1.0000 - loss: 6.6679e-05 - val_accuracy: 0.7111 - val_loss: 2.6092\n",
            "Epoch 30/30\n",
            "27/27 - 22s - 810ms/step - accuracy: 1.0000 - loss: 5.5808e-05 - val_accuracy: 0.7333 - val_loss: 2.6360\n",
            "\n",
            "Entrenando MobileNetV2...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/30\n",
            "27/27 - 11s - 424ms/step - accuracy: 0.5880 - loss: 0.9345 - val_accuracy: 0.7778 - val_loss: 0.6282\n",
            "Epoch 2/30\n",
            "27/27 - 3s - 109ms/step - accuracy: 0.8611 - loss: 0.3611 - val_accuracy: 0.8222 - val_loss: 0.4455\n",
            "Epoch 3/30\n",
            "27/27 - 6s - 211ms/step - accuracy: 0.9352 - loss: 0.2290 - val_accuracy: 0.8444 - val_loss: 0.4871\n",
            "Epoch 4/30\n",
            "27/27 - 3s - 123ms/step - accuracy: 0.9676 - loss: 0.1311 - val_accuracy: 0.8222 - val_loss: 0.4099\n",
            "Epoch 5/30\n",
            "27/27 - 7s - 249ms/step - accuracy: 0.9861 - loss: 0.0861 - val_accuracy: 0.8889 - val_loss: 0.3740\n",
            "Epoch 6/30\n",
            "27/27 - 7s - 241ms/step - accuracy: 0.9954 - loss: 0.0551 - val_accuracy: 0.8667 - val_loss: 0.3976\n",
            "Epoch 7/30\n",
            "27/27 - 5s - 190ms/step - accuracy: 1.0000 - loss: 0.0313 - val_accuracy: 0.8667 - val_loss: 0.4061\n",
            "Epoch 8/30\n",
            "27/27 - 3s - 105ms/step - accuracy: 1.0000 - loss: 0.0259 - val_accuracy: 0.8444 - val_loss: 0.4267\n",
            "Epoch 9/30\n",
            "27/27 - 6s - 217ms/step - accuracy: 1.0000 - loss: 0.0171 - val_accuracy: 0.8444 - val_loss: 0.4637\n",
            "Epoch 10/30\n",
            "27/27 - 6s - 206ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.8444 - val_loss: 0.4750\n",
            "Epoch 11/30\n",
            "27/27 - 10s - 374ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.8444 - val_loss: 0.4937\n",
            "Epoch 12/30\n",
            "27/27 - 8s - 306ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.8444 - val_loss: 0.4701\n",
            "Epoch 13/30\n",
            "27/27 - 5s - 175ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.8444 - val_loss: 0.4883\n",
            "Epoch 14/30\n",
            "27/27 - 6s - 236ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.8444 - val_loss: 0.4923\n",
            "Epoch 15/30\n",
            "27/27 - 4s - 149ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.8444 - val_loss: 0.4949\n",
            "Epoch 16/30\n",
            "27/27 - 3s - 102ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.8444 - val_loss: 0.5202\n",
            "Epoch 17/30\n",
            "27/27 - 6s - 238ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.8444 - val_loss: 0.5082\n",
            "Epoch 18/30\n",
            "27/27 - 4s - 141ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.8444 - val_loss: 0.5065\n",
            "Epoch 19/30\n",
            "27/27 - 5s - 194ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.8444 - val_loss: 0.5238\n",
            "Epoch 20/30\n",
            "27/27 - 4s - 155ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.8444 - val_loss: 0.5263\n",
            "Epoch 21/30\n",
            "27/27 - 3s - 107ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.8444 - val_loss: 0.5408\n",
            "Epoch 22/30\n",
            "27/27 - 3s - 108ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.8444 - val_loss: 0.5402\n",
            "Epoch 23/30\n",
            "27/27 - 7s - 243ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.8444 - val_loss: 0.5334\n",
            "Epoch 24/30\n",
            "27/27 - 3s - 129ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.8444 - val_loss: 0.5460\n",
            "Epoch 25/30\n",
            "27/27 - 3s - 106ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8444 - val_loss: 0.5563\n",
            "Epoch 26/30\n",
            "27/27 - 5s - 198ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8444 - val_loss: 0.5592\n",
            "Epoch 27/30\n",
            "27/27 - 5s - 173ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8444 - val_loss: 0.5679\n",
            "Epoch 28/30\n",
            "27/27 - 3s - 125ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8444 - val_loss: 0.5686\n",
            "Epoch 29/30\n",
            "27/27 - 3s - 109ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8444 - val_loss: 0.5735\n",
            "Epoch 30/30\n",
            "27/27 - 6s - 227ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8444 - val_loss: 0.5794\n",
            "\n",
            "Entrenando ResNet50...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/30\n",
            "27/27 - 27s - 1s/step - accuracy: 0.3796 - loss: 1.1312 - val_accuracy: 0.3333 - val_loss: 1.1107\n",
            "Epoch 2/30\n",
            "27/27 - 17s - 645ms/step - accuracy: 0.3843 - loss: 1.0922 - val_accuracy: 0.3333 - val_loss: 1.1036\n",
            "Epoch 3/30\n",
            "27/27 - 20s - 749ms/step - accuracy: 0.3194 - loss: 1.1007 - val_accuracy: 0.4000 - val_loss: 1.0859\n",
            "Epoch 4/30\n",
            "27/27 - 21s - 781ms/step - accuracy: 0.4120 - loss: 1.0708 - val_accuracy: 0.3778 - val_loss: 1.1009\n",
            "Epoch 5/30\n",
            "27/27 - 20s - 736ms/step - accuracy: 0.3796 - loss: 1.0770 - val_accuracy: 0.3333 - val_loss: 1.1257\n",
            "Epoch 6/30\n",
            "27/27 - 17s - 644ms/step - accuracy: 0.4398 - loss: 1.0605 - val_accuracy: 0.3556 - val_loss: 1.0778\n",
            "Epoch 7/30\n",
            "27/27 - 18s - 672ms/step - accuracy: 0.4722 - loss: 1.0204 - val_accuracy: 0.3333 - val_loss: 1.1171\n",
            "Epoch 8/30\n",
            "27/27 - 20s - 756ms/step - accuracy: 0.4491 - loss: 1.0458 - val_accuracy: 0.3333 - val_loss: 1.1582\n",
            "Epoch 9/30\n",
            "27/27 - 20s - 754ms/step - accuracy: 0.4583 - loss: 1.0441 - val_accuracy: 0.4000 - val_loss: 1.0727\n",
            "Epoch 10/30\n",
            "27/27 - 15s - 554ms/step - accuracy: 0.4630 - loss: 1.0238 - val_accuracy: 0.4000 - val_loss: 1.0632\n",
            "Epoch 11/30\n",
            "27/27 - 20s - 751ms/step - accuracy: 0.4954 - loss: 0.9835 - val_accuracy: 0.4000 - val_loss: 1.0564\n",
            "Epoch 12/30\n",
            "27/27 - 23s - 862ms/step - accuracy: 0.5648 - loss: 0.9637 - val_accuracy: 0.3778 - val_loss: 1.0870\n",
            "Epoch 13/30\n",
            "27/27 - 18s - 656ms/step - accuracy: 0.5185 - loss: 0.9629 - val_accuracy: 0.3556 - val_loss: 1.0720\n",
            "Epoch 14/30\n",
            "27/27 - 20s - 759ms/step - accuracy: 0.5694 - loss: 0.9496 - val_accuracy: 0.3778 - val_loss: 1.1256\n",
            "Epoch 15/30\n",
            "27/27 - 15s - 554ms/step - accuracy: 0.4907 - loss: 0.9771 - val_accuracy: 0.4000 - val_loss: 1.0546\n",
            "Epoch 16/30\n",
            "27/27 - 20s - 758ms/step - accuracy: 0.5972 - loss: 0.9290 - val_accuracy: 0.4444 - val_loss: 1.0449\n",
            "Epoch 17/30\n",
            "27/27 - 20s - 748ms/step - accuracy: 0.6019 - loss: 0.9181 - val_accuracy: 0.4222 - val_loss: 1.0561\n",
            "Epoch 18/30\n",
            "27/27 - 21s - 764ms/step - accuracy: 0.5231 - loss: 0.9485 - val_accuracy: 0.3333 - val_loss: 1.2166\n",
            "Epoch 19/30\n",
            "27/27 - 21s - 765ms/step - accuracy: 0.5231 - loss: 0.9028 - val_accuracy: 0.3556 - val_loss: 1.1013\n",
            "Epoch 20/30\n",
            "27/27 - 20s - 757ms/step - accuracy: 0.5556 - loss: 0.9036 - val_accuracy: 0.4222 - val_loss: 1.0394\n",
            "Epoch 21/30\n",
            "27/27 - 23s - 854ms/step - accuracy: 0.5741 - loss: 0.9038 - val_accuracy: 0.3778 - val_loss: 1.0651\n",
            "Epoch 22/30\n",
            "27/27 - 18s - 653ms/step - accuracy: 0.5972 - loss: 0.8832 - val_accuracy: 0.3556 - val_loss: 1.0456\n",
            "Epoch 23/30\n",
            "27/27 - 21s - 763ms/step - accuracy: 0.5509 - loss: 0.8997 - val_accuracy: 0.3556 - val_loss: 1.2526\n",
            "Epoch 24/30\n",
            "27/27 - 20s - 754ms/step - accuracy: 0.5787 - loss: 0.8652 - val_accuracy: 0.4667 - val_loss: 1.0444\n",
            "Epoch 25/30\n",
            "27/27 - 20s - 756ms/step - accuracy: 0.6620 - loss: 0.8484 - val_accuracy: 0.4000 - val_loss: 1.1202\n",
            "Epoch 26/30\n",
            "27/27 - 15s - 553ms/step - accuracy: 0.5926 - loss: 0.8765 - val_accuracy: 0.4444 - val_loss: 1.0479\n",
            "Epoch 27/30\n",
            "27/27 - 23s - 836ms/step - accuracy: 0.6065 - loss: 0.8575 - val_accuracy: 0.3778 - val_loss: 1.0603\n",
            "Epoch 28/30\n",
            "27/27 - 18s - 673ms/step - accuracy: 0.6343 - loss: 0.8257 - val_accuracy: 0.4000 - val_loss: 1.0491\n",
            "Epoch 29/30\n",
            "27/27 - 15s - 552ms/step - accuracy: 0.6528 - loss: 0.7980 - val_accuracy: 0.4444 - val_loss: 1.0471\n",
            "Epoch 30/30\n",
            "27/27 - 20s - 753ms/step - accuracy: 0.5972 - loss: 0.8184 - val_accuracy: 0.3778 - val_loss: 1.0656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, applications\n",
        "\n",
        "input_shape = (128, 128, 3)\n",
        "num_classes = 3\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# Modelo 1: CNN sencilla\n",
        "def build_cnn_simple(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Modelo 2: CNN más profunda\n",
        "def build_cnn_deep(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "        layers.Conv2D(32, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Modelo 3: MobileNetV2 Transfer Learning\n",
        "def build_mobilenet(input_shape, num_classes):\n",
        "    base = applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    base.trainable = False  # Congelar base\n",
        "    model = models.Sequential([\n",
        "        base,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Modelo 4: ResNet50 Transfer Learning (Nuevo)\n",
        "def build_resnet50(input_shape, num_classes):\n",
        "    base = applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    base.trainable = False # Congelar base\n",
        "    model = models.Sequential([\n",
        "        base,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "print(\"Entrenando CNN Simple...\")\n",
        "cnn_simple = build_cnn_simple(input_shape, num_classes)\n",
        "history1 = cnn_simple.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"\\nEntrenando CNN Profunda...\")\n",
        "cnn_deep = build_cnn_deep(input_shape, num_classes)\n",
        "history2 = cnn_deep.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"\\nEntrenando MobileNetV2...\")\n",
        "mobilenet = build_mobilenet(input_shape, num_classes)\n",
        "history3 = mobilenet.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"\\nEntrenando ResNet50...\")\n",
        "resnet50 = build_resnet50(input_shape, num_classes)\n",
        "history4 = resnet50.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Guardar modelos\n",
        "cnn_simple.save('cnn_simple.h5')\n",
        "cnn_deep.save('cnn_deep.h5')\n",
        "mobilenet.save('mobilenet.h5')\n",
        "resnet50.save('resnet50.h5') # Guardar el nuevo modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P6D8PEfb-WAD",
        "outputId": "0fa133ce-11b8-49eb-dbec-1eafa923e5bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.46.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.46.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit tensorflow pillow scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfMYIipl-ZNC",
        "outputId": "f2f128aa-a208-414a-c337-9a7fc5f40abb",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wkhtmltopdf is already the newest version (0.12.6-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Requirement already satisfied: pdfkit in /usr/local/lib/python3.11/dist-packages (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y wkhtmltopdf\n",
        "!pip install pdfkit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef, accuracy_score\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "from io import BytesIO\n",
        "import base64\n",
        "import os\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime\n",
        "import tempfile\n",
        "import cv2\n",
        "import requests\n",
        "import io\n",
        "\n",
        "try:\n",
        "    import pdfkit\n",
        "    PDFKIT_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PDFKIT_AVAILABLE = False\n",
        "\n",
        "LANGUAGES = {\n",
        "    'es': {'name': 'Español', 'flag': '🇪🇸'},\n",
        "    'en': {'name': 'English', 'flag': '🇺🇸'},\n",
        "    'it': {'name': 'Italiano', 'flag': '🇮🇹'}\n",
        "}\n",
        "\n",
        "TRANSLATIONS = {\n",
        "    'es': {\n",
        "        # Títulos principales\n",
        "        'page_title': 'Diagnóstico Inteligente de Cacao - Deep Learning',\n",
        "        'main_title': 'Diagnóstico Inteligente de Enfermedades del Cacao',\n",
        "        'subtitle': 'Sistema avanzado con modelos deep learning (CNN Simple, CNN Profunda, MobileNetV2, ResNet50/GradCAM)',\n",
        "\n",
        "        # Menús\n",
        "        'control_panel': 'Panel de Control',\n",
        "        'select_mode': 'Seleccionar Modo',\n",
        "        'individual_diagnosis': 'Diagnóstico Individual',\n",
        "        'disease_guide': 'Guía de Enfermedades',\n",
        "        'comparative_analysis': 'Análisis Comparativo',\n",
        "        'system_info': 'Información del Sistema',\n",
        "\n",
        "        # Diagnóstico individual\n",
        "        'select_image_source': 'Selecciona el origen de la imagen',\n",
        "        'upload_from_computer': 'Subir desde mi computadora',\n",
        "        'select_from_github': 'Seleccionar desde GitHub',\n",
        "        'upload_image': 'Suba una imagen de mazorca de cacao para diagnóstico',\n",
        "        'searching_images': 'Buscando imágenes públicas en la raíz del repositorio GitHub...',\n",
        "        'choose_image': 'Elige una imagen',\n",
        "        'load_selected_image': 'Cargar imagen seleccionada',\n",
        "        'image_loaded': 'Imagen cargada',\n",
        "        'automatic_diagnosis': 'Diagnóstico automático con IA',\n",
        "        'processing': 'Procesando...',\n",
        "        'ai_diagnosis': 'Diagnóstico por IA',\n",
        "        'description': 'Descripción',\n",
        "        'severity': 'Severidad',\n",
        "        'gradcam_caption': 'Mapa de calor Grad-CAM (ResNet50)',\n",
        "        'gradcam_description': 'Grad-CAM: Muestra qué regiones de la imagen influyeron más en la predicción del modelo ResNet50.',\n",
        "        'model_confidence': 'Confianza de los modelos',\n",
        "        'treatment_prevention': 'Tratamiento y medidas preventivas',\n",
        "        'recommended_treatment': 'Tratamiento recomendado',\n",
        "        'prevention': 'Prevención',\n",
        "        'image_features': 'Características de la imagen cargada',\n",
        "        'download_report': 'Descargar reporte individual',\n",
        "        'download_html': 'Descargar reporte HTML',\n",
        "        'download_pdf': 'Descargar reporte PDF',\n",
        "\n",
        "        # Características de imagen\n",
        "        'avg_brightness': 'Brillo promedio',\n",
        "        'texture_variance': 'Varianza de textura',\n",
        "        'contrast': 'Contraste',\n",
        "\n",
        "        # Guía de enfermedades\n",
        "        'disease_guide_title': 'Guía Completa de Enfermedades del Cacao',\n",
        "        'example_image': 'Ejemplo de',\n",
        "        'example_not_available': 'Imagen de ejemplo no disponible para',\n",
        "        'general_info': 'Información General',\n",
        "        'symptoms': 'Síntomas Característicos',\n",
        "        'preventive_measures': 'Medidas Preventivas',\n",
        "        'recommended_treatment': 'Tratamiento Recomendado',\n",
        "\n",
        "        # Análisis comparativo\n",
        "        'comparative_analysis_title': 'Análisis Comparativo de Modelos',\n",
        "        'performance_analysis': 'Análisis de Rendimiento',\n",
        "        'generate_report': 'Generar Reporte',\n",
        "        'model_evaluation': 'Evaluación de Modelos de IA',\n",
        "        'instructions': 'Instrucciones',\n",
        "        'download_example': 'Descargar archivo de ejemplo',\n",
        "        'select_csv_source': 'Selecciona el origen del CSV',\n",
        "        'load_csv': 'Cargar archivo de resultados CSV',\n",
        "        'searching_csv': 'Buscando archivos CSV públicos en la raíz del repositorio GitHub...',\n",
        "        'choose_csv': 'Elige un archivo CSV',\n",
        "        'load_selected_csv': 'Cargar CSV seleccionado',\n",
        "        'file_loaded': 'Archivo cargado exitosamente',\n",
        "        'samples_found': 'muestras encontradas',\n",
        "        'best_model': 'El mejor modelo es',\n",
        "        'statistical_analysis': 'Análisis Estadístico (Prueba de McNemar)',\n",
        "        'significant': 'Significativa',\n",
        "        'not_significant': 'No significativa',\n",
        "        'generate_comparative_report': 'Generar Reporte Comparativo',\n",
        "        'generating_report': 'Generando reporte completo...',\n",
        "        'report_generated': 'Reporte PDF generado exitosamente',\n",
        "        'pdfkit_not_available': 'pdfkit no disponible. Descargando como HTML.',\n",
        "\n",
        "        # Métricas\n",
        "        'precision': 'Precisión',\n",
        "        'recall': 'Recall',\n",
        "        'f1_score': 'F1-Score',\n",
        "        'mcc': 'MCC',\n",
        "        'avg_specificity': 'Especificidad Promedio',\n",
        "        'model': 'Modelo',\n",
        "        'confidence': 'Confianza',\n",
        "        'prediction': 'Predicción',\n",
        "\n",
        "        # Enfermedades\n",
        "        'healthy': 'Sano',\n",
        "        'black_pod_rot': 'Pudrición Negra (Black Pod Rot)',\n",
        "        'pod_borer': 'Barrenador de Mazorca (Pod Borer)',\n",
        "\n",
        "        # Mensajes\n",
        "        'error_loading_models': 'Error cargando modelos',\n",
        "        'error_loading_image': 'No se pudo cargar la imagen seleccionada desde GitHub',\n",
        "        'error_loading_csv': 'No se pudo cargar el archivo CSV seleccionado desde GitHub',\n",
        "        'no_images_found': 'No se encontraron imágenes en la raíz del repositorio',\n",
        "        'no_csv_found': 'No se encontraron archivos CSV en la raíz del repositorio',\n",
        "        'csv_loaded_success': 'CSV cargado correctamente desde GitHub',\n",
        "        'image_loaded_success': 'Imagen cargada correctamente desde GitHub',\n",
        "        'analysis_first': 'Primero realiza el análisis en la pestaña Análisis de Rendimiento',\n",
        "        'report_includes': 'El reporte incluirá métricas detalladas, matrices de confusión y análisis estadístico.',\n",
        "\n",
        "        # Información del sistema\n",
        "        'available_models': 'Modelos Disponibles',\n",
        "        'detected_diseases': 'Enfermedades Detectadas',\n",
        "        'healthy_pods': 'Mazorcas Sanas',\n",
        "        'black_rot': 'Pudrición Negra',\n",
        "        'pod_borer_pest': 'Barrenador de Mazorca',\n",
        "\n",
        "        # Severidad\n",
        "        'none': 'Ninguna',\n",
        "        'high': 'Alta',\n",
        "        'medium_high': 'Media-Alta',\n",
        "\n",
        "        # Instrucciones detalladas\n",
        "        'detailed_instructions': [\n",
        "            'Sube un archivo CSV con las columnas: y_true, y_pred1, y_pred2, y_pred3',\n",
        "            'El sistema comparará automáticamente los tres modelos',\n",
        "            'Genera métricas avanzadas y pruebas estadísticas'\n",
        "        ]\n",
        "    },\n",
        "    'en': {\n",
        "        # Main titles\n",
        "        'page_title': 'Intelligent Cacao Diagnosis - Deep Learning',\n",
        "        'main_title': 'Intelligent Cacao Disease Diagnosis',\n",
        "        'subtitle': 'Advanced system with deep learning models (Simple CNN, Deep CNN, MobileNetV2, ResNet50/GradCAM)',\n",
        "\n",
        "        # Menus\n",
        "        'control_panel': 'Control Panel',\n",
        "        'select_mode': 'Select Mode',\n",
        "        'individual_diagnosis': 'Individual Diagnosis',\n",
        "        'disease_guide': 'Disease Guide',\n",
        "        'comparative_analysis': 'Comparative Analysis',\n",
        "        'system_info': 'System Information',\n",
        "\n",
        "        # Individual diagnosis\n",
        "        'select_image_source': 'Select image source',\n",
        "        'upload_from_computer': 'Upload from my computer',\n",
        "        'select_from_github': 'Select from GitHub',\n",
        "        'upload_image': 'Upload a cacao pod image for diagnosis',\n",
        "        'searching_images': 'Searching for public images in the GitHub repository root...',\n",
        "        'choose_image': 'Choose an image',\n",
        "        'load_selected_image': 'Load selected image',\n",
        "        'image_loaded': 'Image loaded',\n",
        "        'automatic_diagnosis': 'Automatic AI diagnosis',\n",
        "        'processing': 'Processing...',\n",
        "        'ai_diagnosis': 'AI Diagnosis',\n",
        "        'description': 'Description',\n",
        "        'severity': 'Severity',\n",
        "        'gradcam_caption': 'Grad-CAM heatmap (ResNet50)',\n",
        "        'gradcam_description': 'Grad-CAM: Shows which regions of the image most influenced the ResNet50 model prediction.',\n",
        "        'model_confidence': 'Model confidence',\n",
        "        'treatment_prevention': 'Treatment and preventive measures',\n",
        "        'recommended_treatment': 'Recommended treatment',\n",
        "        'prevention': 'Prevention',\n",
        "        'image_features': 'Loaded image features',\n",
        "        'download_report': 'Download individual report',\n",
        "        'download_html': 'Download HTML report',\n",
        "        'download_pdf': 'Download PDF report',\n",
        "\n",
        "        # Image features\n",
        "        'avg_brightness': 'Average brightness',\n",
        "        'texture_variance': 'Texture variance',\n",
        "        'contrast': 'Contrast',\n",
        "\n",
        "        # Disease guide\n",
        "        'disease_guide_title': 'Complete Cacao Disease Guide',\n",
        "        'example_image': 'Example of',\n",
        "        'example_not_available': 'Example image not available for',\n",
        "        'general_info': 'General Information',\n",
        "        'symptoms': 'Characteristic Symptoms',\n",
        "        'preventive_measures': 'Preventive Measures',\n",
        "        'recommended_treatment': 'Recommended Treatment',\n",
        "\n",
        "        # Comparative analysis\n",
        "        'comparative_analysis_title': 'Model Comparative Analysis',\n",
        "        'performance_analysis': 'Performance Analysis',\n",
        "        'generate_report': 'Generate Report',\n",
        "        'model_evaluation': 'AI Model Evaluation',\n",
        "        'instructions': 'Instructions',\n",
        "        'download_example': 'Download example file',\n",
        "        'select_csv_source': 'Select CSV source',\n",
        "        'load_csv': 'Load CSV results file',\n",
        "        'searching_csv': 'Searching for public CSV files in the GitHub repository root...',\n",
        "        'choose_csv': 'Choose a CSV file',\n",
        "        'load_selected_csv': 'Load selected CSV',\n",
        "        'file_loaded': 'File loaded successfully',\n",
        "        'samples_found': 'samples found',\n",
        "        'best_model': 'The best model is',\n",
        "        'statistical_analysis': 'Statistical Analysis (McNemar Test)',\n",
        "        'significant': 'Significant',\n",
        "        'not_significant': 'Not significant',\n",
        "        'generate_comparative_report': 'Generate Comparative Report',\n",
        "        'generating_report': 'Generating complete report...',\n",
        "        'report_generated': 'PDF report generated successfully',\n",
        "        'pdfkit_not_available': 'pdfkit not available. Downloading as HTML.',\n",
        "\n",
        "        # Metrics\n",
        "        'precision': 'Precision',\n",
        "        'recall': 'Recall',\n",
        "        'f1_score': 'F1-Score',\n",
        "        'mcc': 'MCC',\n",
        "        'avg_specificity': 'Average Specificity',\n",
        "        'model': 'Model',\n",
        "        'confidence': 'Confidence',\n",
        "        'prediction': 'Prediction',\n",
        "\n",
        "        # Diseases\n",
        "        'healthy': 'Healthy',\n",
        "        'black_pod_rot': 'Black Pod Rot',\n",
        "        'pod_borer': 'Pod Borer',\n",
        "\n",
        "        # Messages\n",
        "        'error_loading_models': 'Error loading models',\n",
        "        'error_loading_image': 'Could not load selected image from GitHub',\n",
        "        'error_loading_csv': 'Could not load selected CSV file from GitHub',\n",
        "        'no_images_found': 'No images found in repository root',\n",
        "        'no_csv_found': 'No CSV files found in repository root',\n",
        "        'csv_loaded_success': 'CSV loaded successfully from GitHub',\n",
        "        'image_loaded_success': 'Image loaded successfully from GitHub',\n",
        "        'analysis_first': 'First perform the analysis in the Performance Analysis tab',\n",
        "        'report_includes': 'The report will include detailed metrics, confusion matrices and statistical analysis.',\n",
        "\n",
        "        # System information\n",
        "        'available_models': 'Available Models',\n",
        "        'detected_diseases': 'Detected Diseases',\n",
        "        'healthy_pods': 'Healthy Pods',\n",
        "        'black_rot': 'Black Rot',\n",
        "        'pod_borer_pest': 'Pod Borer',\n",
        "\n",
        "        # Severity\n",
        "        'none': 'None',\n",
        "        'high': 'High',\n",
        "        'medium_high': 'Medium-High',\n",
        "\n",
        "        # Detailed instructions\n",
        "        'detailed_instructions': [\n",
        "            'Upload a CSV file with columns: y_true, y_pred1, y_pred2, y_pred3',\n",
        "            'The system will automatically compare the three models',\n",
        "            'Generate advanced metrics and statistical tests'\n",
        "        ]\n",
        "    },\n",
        "    'it': {\n",
        "        # Titoli principali\n",
        "        'page_title': 'Diagnosi Intelligente del Cacao - Deep Learning',\n",
        "        'main_title': 'Diagnosi Intelligente delle Malattie del Cacao',\n",
        "        'subtitle': 'Sistema avanzato con modelli deep learning (CNN Semplice, CNN Profonda, MobileNetV2, ResNet50/GradCAM)',\n",
        "\n",
        "        # Menu\n",
        "        'control_panel': 'Pannello di Controllo',\n",
        "        'select_mode': 'Seleziona Modalità',\n",
        "        'individual_diagnosis': 'Diagnosi Individuale',\n",
        "        'disease_guide': 'Guida alle Malattie',\n",
        "        'comparative_analysis': 'Analisi Comparativa',\n",
        "        'system_info': 'Informazioni del Sistema',\n",
        "\n",
        "        # Diagnosi individuale\n",
        "        'select_image_source': 'Seleziona la fonte dell\\'immagine',\n",
        "        'upload_from_computer': 'Carica dal mio computer',\n",
        "        'select_from_github': 'Seleziona da GitHub',\n",
        "        'upload_image': 'Carica un\\'immagine di baccello di cacao per la diagnosi',\n",
        "        'searching_images': 'Ricerca immagini pubbliche nella radice del repository GitHub...',\n",
        "        'choose_image': 'Scegli un\\'immagine',\n",
        "        'load_selected_image': 'Carica immagine selezionata',\n",
        "        'image_loaded': 'Immagine caricata',\n",
        "        'automatic_diagnosis': 'Diagnosi automatica con IA',\n",
        "        'processing': 'Elaborazione...',\n",
        "        'ai_diagnosis': 'Diagnosi IA',\n",
        "        'description': 'Descrizione',\n",
        "        'severity': 'Severità',\n",
        "        'gradcam_caption': 'Mappa di calore Grad-CAM (ResNet50)',\n",
        "        'gradcam_description': 'Grad-CAM: Mostra quali regioni dell\\'immagine hanno influenzato maggiormente la predizione del modello ResNet50.',\n",
        "        'model_confidence': 'Confidenza dei modelli',\n",
        "        'treatment_prevention': 'Trattamento e misure preventive',\n",
        "        'recommended_treatment': 'Trattamento raccomandato',\n",
        "        'prevention': 'Prevenzione',\n",
        "        'image_features': 'Caratteristiche dell\\'immagine caricata',\n",
        "        'download_report': 'Scarica rapporto individuale',\n",
        "        'download_html': 'Scarica rapporto HTML',\n",
        "        'download_pdf': 'Scarica rapporto PDF',\n",
        "\n",
        "        # Caratteristiche immagine\n",
        "        'avg_brightness': 'Luminosità media',\n",
        "        'texture_variance': 'Varianza texture',\n",
        "        'contrast': 'Contrasto',\n",
        "\n",
        "        # Guida malattie\n",
        "        'disease_guide_title': 'Guida Completa alle Malattie del Cacao',\n",
        "        'example_image': 'Esempio di',\n",
        "        'example_not_available': 'Immagine di esempio non disponibile per',\n",
        "        'general_info': 'Informazioni Generali',\n",
        "        'symptoms': 'Sintomi Caratteristici',\n",
        "        'preventive_measures': 'Misure Preventive',\n",
        "        'recommended_treatment': 'Trattamento Raccomandato',\n",
        "\n",
        "        # Analisi comparativa\n",
        "        'comparative_analysis_title': 'Analisi Comparativa dei Modelli',\n",
        "        'performance_analysis': 'Analisi delle Prestazioni',\n",
        "        'generate_report': 'Genera Rapporto',\n",
        "        'model_evaluation': 'Valutazione Modelli IA',\n",
        "        'instructions': 'Istruzioni',\n",
        "        'download_example': 'Scarica file di esempio',\n",
        "        'select_csv_source': 'Seleziona la fonte del CSV',\n",
        "        'load_csv': 'Carica file CSV dei risultati',\n",
        "        'searching_csv': 'Ricerca file CSV pubblici nella radice del repository GitHub...',\n",
        "        'choose_csv': 'Scegli un file CSV',\n",
        "        'load_selected_csv': 'Carica CSV selezionato',\n",
        "        'file_loaded': 'File caricato con successo',\n",
        "        'samples_found': 'campioni trovati',\n",
        "        'best_model': 'Il modello migliore è',\n",
        "        'statistical_analysis': 'Analisi Statistica (Test di McNemar)',\n",
        "        'significant': 'Significativa',\n",
        "        'not_significant': 'Non significativa',\n",
        "        'generate_comparative_report': 'Genera Rapporto Comparativo',\n",
        "        'generating_report': 'Generazione rapporto completo...',\n",
        "        'report_generated': 'Rapporto PDF generato con successo',\n",
        "        'pdfkit_not_available': 'pdfkit non disponibile. Scaricando come HTML.',\n",
        "\n",
        "        # Metriche\n",
        "        'precision': 'Precisione',\n",
        "        'recall': 'Richiamo',\n",
        "        'f1_score': 'F1-Score',\n",
        "        'mcc': 'MCC',\n",
        "        'avg_specificity': 'Specificità Media',\n",
        "        'model': 'Modello',\n",
        "        'confidence': 'Confidenza',\n",
        "        'prediction': 'Predizione',\n",
        "\n",
        "        # Malattie\n",
        "        'healthy': 'Sano',\n",
        "        'black_pod_rot': 'Marciume Nero del Baccello',\n",
        "        'pod_borer': 'Perforatore del Baccello',\n",
        "\n",
        "        # Messaggi\n",
        "        'error_loading_models': 'Errore nel caricamento dei modelli',\n",
        "        'error_loading_image': 'Impossibile caricare l\\'immagine selezionata da GitHub',\n",
        "        'error_loading_csv': 'Impossibile caricare il file CSV selezionato da GitHub',\n",
        "        'no_images_found': 'Nessuna immagine trovata nella radice del repository',\n",
        "        'no_csv_found': 'Nessun file CSV trovato nella radice del repository',\n",
        "        'csv_loaded_success': 'CSV caricato con successo da GitHub',\n",
        "        'image_loaded_success': 'Immagine caricata con successo da GitHub',\n",
        "        'analysis_first': 'Prima esegui l\\'analisi nella scheda Analisi delle Prestazioni',\n",
        "        'report_includes': 'Il rapporto includerà metriche dettagliate, matrici di confusione e analisi statistica.',\n",
        "\n",
        "        # Informazioni sistema\n",
        "        'available_models': 'Modelli Disponibili',\n",
        "        'detected_diseases': 'Malattie Rilevate',\n",
        "        'healthy_pods': 'Baccelli Sani',\n",
        "        'black_rot': 'Marciume Nero',\n",
        "        'pod_borer_pest': 'Perforatore del Baccello',\n",
        "\n",
        "        # Severità\n",
        "        'none': 'Nessuna',\n",
        "        'high': 'Alta',\n",
        "        'medium_high': 'Media-Alta',\n",
        "\n",
        "        # Istruzioni dettagliate\n",
        "        'detailed_instructions': [\n",
        "            'Carica un file CSV con le colonne: y_true, y_pred1, y_pred2, y_pred3',\n",
        "            'Il sistema confronterà automaticamente i tre modelli',\n",
        "            'Genera metriche avanzate e test statistici'\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "def get_text(key, lang='es'):\n",
        "    return TRANSLATIONS.get(lang, TRANSLATIONS['es']).get(key, key)\n",
        "\n",
        "def init_language():\n",
        "    if 'language' not in st.session_state:\n",
        "        st.session_state.language = 'es'\n",
        "\n",
        "def language_selector():\n",
        "    st.sidebar.markdown(\"### 🌐 Idioma / Language / Lingua\")\n",
        "    language_options = [f\"{LANGUAGES[lang]['flag']} {LANGUAGES[lang]['name']}\" for lang in LANGUAGES.keys()]\n",
        "    current_lang_index = list(LANGUAGES.keys()).index(st.session_state.language)\n",
        "    selected_lang = st.sidebar.selectbox(\n",
        "        \"Seleccionar idioma\",\n",
        "        language_options,\n",
        "        index=current_lang_index,\n",
        "        key=\"language_selector\"\n",
        "    )\n",
        "    selected_lang_code = list(LANGUAGES.keys())[language_options.index(selected_lang)]\n",
        "    if selected_lang_code != st.session_state.language:\n",
        "        st.session_state.language = selected_lang_code\n",
        "        st.rerun()\n",
        "\n",
        "GITHUB_USER = \"DanteVas\"\n",
        "GITHUB_REPO = \"Sistema-de-diagnostico-de-enfermedades-del-cacao-usando-deep-learning\"\n",
        "GITHUB_IMG_FOLDER = \"\"\n",
        "\n",
        "def listar_imagenes_github(user, repo, carpeta):\n",
        "    api_url = f\"https://api.github.com/repos/{user}/{repo}/contents/{carpeta}\".rstrip(\"/\")\n",
        "    r = requests.get(api_url)\n",
        "    files = []\n",
        "    if r.status_code == 200:\n",
        "        content = r.json()\n",
        "        for file in content:\n",
        "            if file['type'] == 'file' and (file['name'].lower().endswith('.jpg') or file['name'].lower().endswith('.png')):\n",
        "                files.append(file['name'])\n",
        "    return files\n",
        "\n",
        "def listar_archivos_github(user, repo, carpeta, extensiones):\n",
        "    api_url = f\"https://api.github.com/repos/{user}/{repo}/contents/{carpeta}\".rstrip(\"/\")\n",
        "    r = requests.get(api_url)\n",
        "    files = []\n",
        "    if r.status_code == 200:\n",
        "        content = r.json()\n",
        "        for file in content:\n",
        "            if file['type'] == 'file' and any(file['name'].lower().endswith(ext) for ext in extensiones):\n",
        "                files.append(file['name'])\n",
        "    return files\n",
        "\n",
        "def get_github_image_url(user, repo, carpeta, filename):\n",
        "    if carpeta == \"\":\n",
        "        return f\"https://raw.githubusercontent.com/{user}/{repo}/main/{filename}\"\n",
        "    else:\n",
        "        return f\"https://raw.githubusercontent.com/{user}/{repo}/main/{carpeta}/{filename}\"\n",
        "\n",
        "def cargar_imagen_desde_github(url):\n",
        "    r = requests.get(url)\n",
        "    if r.status_code == 200:\n",
        "        return Image.open(BytesIO(r.content)).convert(\"RGB\")\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "DISEASE_INFO = {\n",
        "    0: {'name': 'Sano', 'desc': 'Mazorca sin síntomas evidentes. Color uniforme y sin lesiones visibles.',\n",
        "        'treatment': 'No requiere tratamiento. Mantenga prácticas agrícolas preventivas.',\n",
        "        'symptoms': 'Fruto y hoja sin manchas ni daños.',\n",
        "        'prevention': 'Mantener buen drenaje, inspección regular, manejo integrado de plagas.',\n",
        "        'severity': 'Ninguna', 'color': '#43A047', 'bg': '#E9FCE7', 'class': 'healthy'},\n",
        "    1: {'name': 'Pudrición Negra (Black Pod Rot)', 'desc': 'Enfermedad causada por Phytophthora spp., con manchas marrón-negruzcas, generalmente en la base o extremo de la mazorca.',\n",
        "        'treatment': '1. Retirar y destruir frutos enfermos\\n2. Aplicar fungicidas (a base de cobre)\\n3. Mejorar el drenaje del suelo\\n4. Podar ramas bajas\\n5. Aplicar materia orgánica',\n",
        "        'symptoms': 'Manchas marrón oscuro o negras, consistencia húmeda, progresión rápida.',\n",
        "        'prevention': 'Mejorar ventilación, evitar humedad excesiva, aplicar fungicidas preventivos.',\n",
        "        'severity': 'Alta', 'color': '#6D4C41', 'bg': '#F9ECE4', 'class': 'pudricion'},\n",
        "    2: {'name': 'Barrenador de Mazorca (Pod Borer)', 'desc': 'Plaga causada por larvas que se alimentan del interior de la mazorca. Provoca daños internos, galerías y pérdida de semillas.',\n",
        "        'treatment': '1. Recolectar y destruir frutos infestados\\n2. Uso de trampas de feromonas\\n3. Control biológico\\n4. Aplicaciones de insecticidas específicos\\n5. Limpieza del cultivo',\n",
        "        'symptoms': 'Orificios pequeños, daños en semillas, frutos deformados, presencia de larvas.',\n",
        "        'prevention': 'Monitoreo con trampas, control biológico, manejo de residuos.',\n",
        "        'severity': 'Media-Alta', 'color': '#FFB300', 'bg': '#FFF8E1', 'class': 'barrenador'}\n",
        "}\n",
        "CLASSES = [DISEASE_INFO[i]['name'] for i in range(3)]\n",
        "MODEL_NAMES = ['CNN Simple', 'CNN Profunda', 'MobileNetV2']\n",
        "IMG_HEIGHT_GRADCAM, IMG_WIDTH_GRADCAM = 224, 224\n",
        "\n",
        "METRIC_DESCRIPTIONS = {\n",
        "    \"Precisión\": \"Porcentaje de predicciones correctas sobre el total de muestras.\",\n",
        "    \"Recall\": \"Capacidad del modelo para encontrar todos los casos positivos (sensibilidad).\",\n",
        "    \"F1-Score\": \"Promedio armónico entre precisión y recall; balance entre falsos positivos y negativos.\",\n",
        "    \"MCC\": \"Medida global de calidad del modelo (-1 a 1, donde 1 es perfecto, 0 es azar).\",\n",
        "    \"Especificidad Promedio\": \"Capacidad de identificar correctamente los negativos (verdaderos negativos / (verdaderos negativos + falsos positivos)).\"\n",
        "}\n",
        "\n",
        "def plot_confusion_matrix_mpl(y_true, y_pred, classes, title='Matriz de Confusión'):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(4, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=classes, yticklabels=classes, ax=ax)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('Predicho')\n",
        "    ax.set_ylabel('Real')\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def fig_to_base64(fig):\n",
        "    buf = BytesIO()\n",
        "    fig.savefig(buf, format=\"png\")\n",
        "    buf.seek(0)\n",
        "    img_base64 = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
        "    plt.close(fig)\n",
        "    return img_base64\n",
        "\n",
        "def create_confidence_chart(predictions, model_names):\n",
        "    df_conf = pd.DataFrame({\n",
        "        'Modelo': model_names,\n",
        "        'Confianza': [float(np.max(pred)) * 100 for pred in predictions],\n",
        "        'Predicción': [CLASSES[int(np.argmax(pred))] for pred in predictions]\n",
        "    })\n",
        "    fig = px.bar(df_conf, x='Modelo', y='Confianza',\n",
        "                 color='Predicción',\n",
        "                 title='Confianza por Modelo',\n",
        "                 color_discrete_map={\n",
        "                     'Sano': '#43A047',\n",
        "                     'Pudrición Negra (Black Pod Rot)': '#6D4C41',\n",
        "                     'Barrenador de Mazorca (Pod Borer)': '#FFB300'\n",
        "                 })\n",
        "    fig.update_layout(height=400)\n",
        "    return fig\n",
        "\n",
        "def mcc_per_class(y_true, y_pred, n_classes=3):\n",
        "    mccs = []\n",
        "    for c in range(n_classes):\n",
        "        y_true_bin = (np.array(y_true) == c).astype(int)\n",
        "        y_pred_bin = (np.array(y_pred) == c).astype(int)\n",
        "        mcc = matthews_corrcoef(y_true_bin, y_pred_bin)\n",
        "        mccs.append(mcc)\n",
        "    return mccs\n",
        "\n",
        "def calculate_advanced_metrics(y_true, y_pred):\n",
        "    report = classification_report(y_true, y_pred, target_names=CLASSES, output_dict=True)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    specificity = []\n",
        "    for i in range(len(CLASSES)):\n",
        "        tn = np.sum(cm) - (np.sum(cm[i, :]) + np.sum(cm[:, i]) - cm[i, i])\n",
        "        fp = np.sum(cm[:, i]) - cm[i, i]\n",
        "        spec = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        specificity.append(spec)\n",
        "    return {\n",
        "        'report': report,\n",
        "        'specificity': specificity,\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'mcc': matthews_corrcoef(y_true, y_pred),\n",
        "        'mcc_per_class': mcc_per_class(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "def mcnemar_test(y_true, y_pred1, y_pred2):\n",
        "    table = np.zeros((2, 2))\n",
        "    for t, p1, p2 in zip(y_true, y_pred1, y_pred2):\n",
        "        if p1 == t and p2 != t:\n",
        "            table[0, 1] += 1\n",
        "        elif p1 != t and p2 == t:\n",
        "            table[1, 0] += 1\n",
        "    try:\n",
        "        result = mcnemar(table, exact=True)\n",
        "        return result.statistic, result.pvalue\n",
        "    except:\n",
        "        return 0, 1\n",
        "\n",
        "def preprocess_image(image, target_size=(128, 128)):\n",
        "    img = np.array(image)\n",
        "    if img.shape[-1] == 4:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\n",
        "    try:\n",
        "        img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        img_resized = cv2.resize(img_bgr, target_size)\n",
        "        lab = cv2.cvtColor(img_resized, cv2.COLOR_BGR2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "        cl = clahe.apply(l)\n",
        "        limg = cv2.merge((cl, a, b))\n",
        "        img_processed = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
        "    except Exception:\n",
        "        img_processed = Image.fromarray(img).resize(target_size)\n",
        "        img_processed = np.array(img_processed)\n",
        "    img_processed = img_processed / 255.0\n",
        "    return np.expand_dims(img_processed, axis=0)\n",
        "\n",
        "def analyze_image_features(image):\n",
        "    img_array = np.array(image)\n",
        "    avg_color = np.mean(img_array, axis=(0, 1))\n",
        "    brightness = np.mean(avg_color)\n",
        "    gray = np.mean(img_array, axis=2)\n",
        "    texture_variance = np.var(gray)\n",
        "    contrast = np.std(gray)\n",
        "    return {\n",
        "        'brightness': brightness,\n",
        "        'texture_variance': texture_variance,\n",
        "        'contrast': contrast,\n",
        "        'avg_color': avg_color.tolist()\n",
        "    }\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    img_array = tf.cast(img_array, tf.float32)\n",
        "    grad_model = Model(\n",
        "        inputs=model.inputs,\n",
        "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    max_val = tf.reduce_max(heatmap)\n",
        "    if max_val == 0:\n",
        "        heatmap = heatmap\n",
        "    else:\n",
        "        heatmap = tf.maximum(heatmap, 0) / max_val\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def superimpose_heatmap(original_img_pil, heatmap):\n",
        "    img_display = np.array(original_img_pil.convert(\"RGB\"))\n",
        "    heatmap_resized = cv2.resize(heatmap, (img_display.shape[1], img_display.shape[0]))\n",
        "    heatmap_resized = np.uint8(255 * heatmap_resized)\n",
        "    colormap = plt.cm.jet\n",
        "    heatmap_colored = colormap(heatmap_resized)[:, :, :3]\n",
        "    heatmap_colored = (heatmap_colored * 255).astype(np.uint8)\n",
        "    alpha = 0.4\n",
        "    superimposed_img = cv2.addWeighted(img_display, 1 - alpha, heatmap_colored, alpha, 0)\n",
        "    return Image.fromarray(superimposed_img)\n",
        "\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "    try:\n",
        "        model1 = load_model('cnn_simple.h5')\n",
        "        model2 = load_model('cnn_deep.h5')\n",
        "        model3 = load_model('mobilenet.h5')\n",
        "        base_model_resnet = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT_GRADCAM, IMG_WIDTH_GRADCAM, 3))\n",
        "        base_model_resnet.trainable = False\n",
        "        model_resnet_for_gradcam = tf.keras.Sequential([\n",
        "            base_model_resnet,\n",
        "            tf.keras.layers.GlobalAveragePooling2D(),\n",
        "            tf.keras.layers.Dense(256, activation='relu'),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
        "        ])\n",
        "        model_resnet_for_gradcam.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        return model1, model2, model3, model_resnet_for_gradcam, base_model_resnet\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error cargando modelos: {e}\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "def generate_html_download(html_content, filename_prefix=\"reporte\", lang=\"es\"):\n",
        "    b64 = base64.b64encode(html_content.encode()).decode()\n",
        "    href = f'<a href=\"data:text/html;base64,{b64}\" download=\"{filename_prefix}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.html\">{get_text(\"download_html\", lang)}</a>'\n",
        "    st.markdown(href, unsafe_allow_html=True)\n",
        "\n",
        "def generate_pdf_report(html_content, filename_prefix=\"reporte\", lang=\"es\"):\n",
        "    if PDFKIT_AVAILABLE:\n",
        "        tmp_html = tempfile.NamedTemporaryFile(delete=False, suffix=\".html\")\n",
        "        tmp_html.write(html_content.encode('utf-8'))\n",
        "        tmp_html.close()\n",
        "        pdf_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\")\n",
        "        pdfkit.from_file(tmp_html.name, pdf_file.name)\n",
        "        pdf_file.close()\n",
        "        with open(pdf_file.name, \"rb\") as f:\n",
        "            st.download_button(\n",
        "                label=f\"📄 {get_text('download_pdf', lang)}\",\n",
        "                data=f,\n",
        "                file_name=f\"{filename_prefix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf\",\n",
        "                mime=\"application/pdf\"\n",
        "            )\n",
        "        os.unlink(tmp_html.name)\n",
        "        os.unlink(pdf_file.name)\n",
        "    else:\n",
        "        st.info(get_text(\"pdfkit_not_available\", lang))\n",
        "\n",
        "def generate_individual_report(image, predictions, features, consensus, lang):\n",
        "    buffered = BytesIO()\n",
        "    image.save(buffered, format=\"PNG\")\n",
        "    img_base64 = base64.b64encode(buffered.getvalue()).decode()\n",
        "    img_html = f'<img src=\"data:image/png;base64,{img_base64}\" style=\"max-width: 300px; border-radius: 12px; margin: 16px auto; display: block;\">'\n",
        "    gradcam_html = \"\"\n",
        "    if 'gradcam_img_base64' in st.session_state:\n",
        "        gradcam_html = f\"\"\"\n",
        "        <div class=\"section\">\n",
        "            <h2>{get_text(\"gradcam_caption\", lang)}</h2>\n",
        "            <img src=\"data:image/png;base64,{st.session_state.gradcam_img_base64}\" style=\"max-width: 500px; border-radius: 12px; margin: 16px auto; display: block;\">\n",
        "            <p style=\"text-align: center; font-style: italic;\">{get_text(\"gradcam_description\", lang)}</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    html = f\"\"\"\n",
        "    <html>\n",
        "    <head>\n",
        "    <meta charset=\"utf-8\">\n",
        "    <title>{get_text('download_report', lang)} - Cacao</title>\n",
        "    <style>\n",
        "    body {{\n",
        "        font-family: 'Segoe UI', Arial, sans-serif;\n",
        "        margin: 32px;\n",
        "        background: #FAF6F0;\n",
        "        color: #333;\n",
        "    }}\n",
        "    .header {{\n",
        "        text-align: center;\n",
        "        margin-bottom: 40px;\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "        padding: 30px;\n",
        "        border-radius: 15px;\n",
        "    }}\n",
        "    .main-title {{\n",
        "        font-size: 2.5em;\n",
        "        margin: 0;\n",
        "        font-weight: 700;\n",
        "    }}\n",
        "    .subtitle {{\n",
        "        font-size: 1.2em;\n",
        "        margin: 10px 0 0 0;\n",
        "        opacity: 0.9;\n",
        "    }}\n",
        "    .section {{\n",
        "        background: white;\n",
        "        padding: 25px;\n",
        "        margin: 20px 0;\n",
        "        border-radius: 15px;\n",
        "        box-shadow: 0 4px 20px rgba(0,0,0,0.1);\n",
        "    }}\n",
        "    .diagnosis-card {{\n",
        "        background: linear-gradient(135deg, #4CAF50 0%, #45a049 100%);\n",
        "        color: white;\n",
        "        padding: 25px;\n",
        "        border-radius: 15px;\n",
        "        margin: 20px 0;\n",
        "        text-align: center;\n",
        "    }}\n",
        "    table {{\n",
        "        width: 100%;\n",
        "        border-collapse: collapse;\n",
        "        margin: 20px 0;\n",
        "    }}\n",
        "    th, td {{\n",
        "        padding: 12px;\n",
        "        text-align: left;\n",
        "        border-bottom: 1px solid #ddd;\n",
        "    }}\n",
        "    th {{\n",
        "        background: #B9F6CA;\n",
        "        color: #2E7D32;\n",
        "        font-weight: 600;\n",
        "    }}\n",
        "    .footer {{\n",
        "        text-align: center;\n",
        "        margin-top: 40px;\n",
        "        color: #666;\n",
        "        font-size: 0.9em;\n",
        "    }}\n",
        "    .feature-box {{\n",
        "        display: inline-block;\n",
        "        margin: 10px;\n",
        "        padding: 15px;\n",
        "        background: #f0f8ff;\n",
        "        border-radius: 10px;\n",
        "        text-align: center;\n",
        "    }}\n",
        "    </style>\n",
        "    </head>\n",
        "    <body>\n",
        "    <div class=\"header\">\n",
        "    <h1 class=\"main-title\"> 🍫  {get_text('download_report', lang)}</h1>\n",
        "    <p class=\"subtitle\">{get_text('report_generated', lang)} {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}</p>\n",
        "    </div>\n",
        "    {img_html}\n",
        "    \"\"\"\n",
        "    disease = DISEASE_INFO[consensus]\n",
        "    html += f\"\"\"\n",
        "    <div class=\"diagnosis-card\">\n",
        "    <h2>{get_text('ai_diagnosis', lang)}: {disease['name']}</h2>\n",
        "    <p style=\"font-size: 1.2em; margin: 10px 0;\">{disease['desc']}</p>\n",
        "    <p><strong>{get_text('severity', lang)}:</strong> {disease['severity']}</p>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    html += f\"\"\"\n",
        "    <div class=\"section\">\n",
        "    <h2>{get_text('model_confidence', lang)}</h2>\n",
        "    <div style=\"text-align: center;\">\n",
        "    \"\"\"\n",
        "    for i, (pred, name) in enumerate(zip(predictions, MODEL_NAMES)):\n",
        "        idx = int(np.argmax(pred))\n",
        "        conf = float(np.max(pred)) * 100\n",
        "        pred_disease = DISEASE_INFO[idx]\n",
        "        html += f\"\"\"\n",
        "        <div class=\"model-result\">\n",
        "        <h3>{name}</h3>\n",
        "        <p><strong>{get_text('prediction', lang)}:</strong> {pred_disease['name']}</p>\n",
        "        <p><strong>{get_text('confidence', lang)}:</strong> {conf:.1f}%</p>\n",
        "        <div class=\"confidence-bar\">\n",
        "        <div class=\"confidence-fill\" style=\"width: {conf}%;\"></div>\n",
        "        </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    html += \"\"\"\n",
        "    </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    html += f\"\"\"\n",
        "    <div class=\"section\">\n",
        "    <h2>{get_text('image_features', lang)}</h2>\n",
        "    <div style=\"text-align: center;\">\n",
        "    <div class=\"feature-box\">\n",
        "    <h4>{get_text('avg_brightness', lang)}</h4>\n",
        "    <p>{features['brightness']:.2f}</p>\n",
        "    </div>\n",
        "    <div class=\"feature-box\">\n",
        "    <h4>{get_text('texture_variance', lang)}</h4>\n",
        "    <p>{features['texture_variance']:.2f}</p>\n",
        "    </div>\n",
        "    <div class=\"feature-box\">\n",
        "    <h4>{get_text('contrast', lang)}</h4>\n",
        "    <p>{features['contrast']:.2f}</p>\n",
        "    </div>\n",
        "    </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    html += gradcam_html\n",
        "    html += f\"\"\"\n",
        "    <div class=\"section\">\n",
        "    <h2>{get_text('recommended_treatment', lang)}</h2>\n",
        "    <pre style=\"white-space: pre-wrap; font-family: inherit;\">{disease['treatment']}</pre>\n",
        "    <h3>{get_text('prevention', lang)}</h3>\n",
        "    <p>{disease['prevention']}</p>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    html += f\"\"\"\n",
        "    <div class=\"section\">\n",
        "    <h2>{get_text('model_confidence', lang)}</h2>\n",
        "    <table>\n",
        "    <tr><th>{get_text('model', lang)}</th><th>{get_text('confidence', lang)}</th></tr>\n",
        "    \"\"\"\n",
        "    avg_probs = np.mean(predictions, axis=0)\n",
        "    for i, (class_name, prob) in enumerate(zip(CLASSES, avg_probs)):\n",
        "        html += f\"<tr><td>{class_name}</td><td>{prob*100:.2f}%</td></tr>\"\n",
        "    html += \"\"\"\n",
        "    </table>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    html += f\"\"\"\n",
        "    <div class=\"footer\">\n",
        "    <p>Desarrollado por Galdos Hilda y Dante Vásquez © {datetime.now().year}</p>\n",
        "    <p>Sistema de Diagnóstico Inteligente para Enfermedades del Cacao</p>\n",
        "    </div>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "    return html\n",
        "\n",
        "def interpret_mcc(mcc, lang):\n",
        "    if mcc > 0.8:\n",
        "        return get_text(\"mcc_interpret_excellent\", lang) if \"mcc_interpret_excellent\" in TRANSLATIONS[lang] else \"Excelente capacidad de discriminación (MCC alto)\"\n",
        "    elif mcc > 0.6:\n",
        "        return get_text(\"mcc_interpret_good\", lang) if \"mcc_interpret_good\" in TRANSLATIONS[lang] else \"Buena capacidad de discriminación\"\n",
        "    elif mcc > 0.4:\n",
        "        return get_text(\"mcc_interpret_moderate\", lang) if \"mcc_interpret_moderate\" in TRANSLATIONS[lang] else \"Moderada capacidad de discriminación\"\n",
        "    elif mcc > 0.2:\n",
        "        return get_text(\"mcc_interpret_weak\", lang) if \"mcc_interpret_weak\" in TRANSLATIONS[lang] else \"Débil capacidad de discriminación\"\n",
        "    else:\n",
        "        return get_text(\"mcc_interpret_poor\", lang) if \"mcc_interpret_poor\" in TRANSLATIONS[lang] else \"Pobre capacidad de discriminación (similar al azar)\"\n",
        "\n",
        "def generate_comparative_report(metrics, confusion_images, model_names, y_true, predictions, lang):\n",
        "    mccs = [m['mcc'] for m in metrics[:len(model_names)]]\n",
        "    best_idx = int(np.argmax(mccs))\n",
        "    best_model = model_names[best_idx]\n",
        "    html = f\"\"\"\n",
        "    <html>\n",
        "    <head>\n",
        "    <meta charset=\"utf-8\">\n",
        "    <title>{get_text('comparative_analysis_title', lang)}</title>\n",
        "    <style>\n",
        "        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 32px; background: #FAF6F0; color: #333; }}\n",
        "        h1 {{ color: #4E342E; font-size: 2.2em; }}\n",
        "        h2 {{ color: #388e3c; margin-top: 36px; }}\n",
        "        table, th, td {{ border: 1px solid #999; border-collapse: collapse; }}\n",
        "        th, td {{ padding: 9px 14px; }}\n",
        "        th {{ background: #B9F6CA; color: #2E7D32; font-weight: 600; }}\n",
        "        .img-box {{ display:inline-block; margin:10px; border-radius:8px; box-shadow:0 4px 12px #0001; background:#fff; }}\n",
        "        .footer {{font-size: 0.95em; color: #888; margin-top: 2em; text-align: center;}}\n",
        "        .card-title {{ font-size: 1.2em; font-weight: 700; margin-top: 14px; color: #4E342E; }}\n",
        "        .desc-block {{ background: #f7fbe7; border-radius: 8px; padding: 12px 18px; margin-bottom: 15px; border-left: 5px solid #7bc043; }}\n",
        "    </style>\n",
        "    </head>\n",
        "    <body>\n",
        "        <h1>{get_text('comparative_analysis_title', lang)}</h1>\n",
        "        <p>{get_text('report_generated', lang)} {datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")}</p>\n",
        "        <div class=\"desc-block\">\n",
        "            <h3>{get_text('performance_analysis', lang)}</h3>\n",
        "            <ul>\n",
        "                <li><b>{get_text('precision', lang)}:</b> {METRIC_DESCRIPTIONS['Precisión']}</li>\n",
        "                <li><b>{get_text('recall', lang)}:</b> {METRIC_DESCRIPTIONS['Recall']}</li>\n",
        "                <li><b>{get_text('f1_score', lang)}:</b> {METRIC_DESCRIPTIONS['F1-Score']}</li>\n",
        "                <li><b>{get_text('mcc', lang)}:</b> {METRIC_DESCRIPTIONS['MCC']}</li>\n",
        "                <li><b>{get_text('avg_specificity', lang)}:</b> {METRIC_DESCRIPTIONS['Especificidad Promedio']}</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "        <h2>{get_text('performance_analysis', lang)}</h2>\n",
        "        <table>\n",
        "            <tr>\n",
        "                <th>{get_text('model', lang)}</th>\n",
        "                <th>{get_text('precision', lang)}</th>\n",
        "                <th>{get_text('recall', lang)}</th>\n",
        "                <th>{get_text('f1_score', lang)}</th>\n",
        "                <th>{get_text('mcc', lang)}</th>\n",
        "                <th>Interpretación MCC</th>\n",
        "                <th>{get_text('avg_specificity', lang)}</th>\n",
        "            </tr>\n",
        "    \"\"\"\n",
        "    n_models = min(len(model_names), len(metrics))\n",
        "    for i in range(n_models):\n",
        "        html += f\"<tr><td>{model_names[i]}</td>\"\n",
        "        html += f\"<td>{metrics[i]['accuracy']:.3f}</td>\"\n",
        "        html += f\"<td>{metrics[i]['report']['macro avg']['recall']:.3f}</td>\"\n",
        "        html += f\"<td>{metrics[i]['report']['macro avg']['f1-score']:.3f}</td>\"\n",
        "        html += f\"<td>{metrics[i]['mcc']:.3f}</td>\"\n",
        "        html += f\"<td>{interpret_mcc(metrics[i]['mcc'], lang)}</td>\"\n",
        "        html += f\"<td>{np.mean(metrics[i]['specificity']):.3f}</td></tr>\"\n",
        "    html += \"</table>\"\n",
        "\n",
        "    html += f\"<p><b>{get_text('best_model', lang)}:</b> <b>{best_model}</b></p>\"\n",
        "\n",
        "    html += f\"<h2>{get_text('mcc', lang)} por clase</h2>\"\n",
        "    html += f\"<p>{get_text('mcc', lang)} por clase mide la capacidad del modelo para distinguir correctamente cada clase frente al resto.</p>\"\n",
        "    html += f\"<table><tr><th>{get_text('model', lang)}</th>\"\n",
        "    for idx, name in enumerate(metrics[0]['report']):\n",
        "        if name in [\"accuracy\", \"macro avg\", \"weighted avg\"]:\n",
        "            continue\n",
        "        html += f\"<th>{name}</th>\"\n",
        "    html += \"</tr>\"\n",
        "    for i in range(n_models):\n",
        "        html += f\"<tr><td>{model_names[i]}</td>\"\n",
        "        for mcc_class in metrics[i]['mcc_per_class']:\n",
        "            html += f\"<td>{mcc_class:.3f}</td>\"\n",
        "        html += \"</tr>\"\n",
        "    html += \"</table>\"\n",
        "\n",
        "    html += f\"<h2>{get_text('statistical_analysis', lang)}</h2><p>{get_text('report_includes', lang)}</p>\"\n",
        "    for i in range(n_models):\n",
        "        html += f\"<li><b>{model_names[i]} - {get_text('mcc', lang)}:</b> {metrics[i]['mcc']:.3f} &rarr; {interpret_mcc(metrics[i]['mcc'], lang)}.</li>\"\n",
        "\n",
        "    html += f\"<br><b>{get_text('statistical_analysis', lang)}:</b> {get_text('best_model', lang)} ({best_model})\"\n",
        "    for i in range(n_models):\n",
        "        if i == best_idx:\n",
        "            continue\n",
        "        stat, pval = mcnemar_test(y_true, predictions[best_idx], predictions[i])\n",
        "        if pval < 0.05:\n",
        "            conclusion = f\"<b>{get_text('significant', lang)}</b>\"\n",
        "        else:\n",
        "            conclusion = f\"<b>{get_text('not_significant', lang)}</b>\"\n",
        "        html += f\"<li>{best_model} vs {model_names[i]}: Estadístico = {stat:.3f}, p-valor = {pval:.4f}. {conclusion}</li>\"\n",
        "    html += \"\"\"\n",
        "    </ul>\n",
        "    <div style='background:#f9fbe7; padding:10px; border-radius:8px;'>\n",
        "        <b>Interpretación:</b> Un p-valor menor a 0.05 indica que existen diferencias estadísticas relevantes en el desempeño entre los modelos comparados.\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    html += f\"\"\"\n",
        "        <div class=\"footer\">\n",
        "            <p>Desarrollado por Galdos Hilda y Dante Vásquez © {datetime.now().year}</p>\n",
        "            <p>Sistema de Diagnóstico Inteligente para Enfermedades del Cacao</p>\n",
        "        </div>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "    return html\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Diagnóstico Inteligente de Cacao - Deep Learning\",\n",
        "    page_icon=\"🍫\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "init_language()\n",
        "language_selector()\n",
        "lang = st.session_state.language\n",
        "\n",
        "st.sidebar.markdown(\"### 🎛️ Panel de Control\")\n",
        "app_mode = st.sidebar.selectbox(\n",
        "    get_text(\"select_mode\", lang),\n",
        "    [\"🔍 \" + get_text('individual_diagnosis', lang), \"📚 \" + get_text('disease_guide', lang), \"📊 \" + get_text('comparative_analysis', lang)],\n",
        "    help=get_text(\"select_mode\", lang)\n",
        ")\n",
        "\n",
        "st.sidebar.markdown(\"---\")\n",
        "st.sidebar.markdown(\"### 📋 \" + get_text(\"system_info\", lang))\n",
        "st.sidebar.info(f\"\"\"\n",
        "**{get_text('available_models', lang)}:**\n",
        "- CNN Simple\n",
        "- CNN Profunda\n",
        "- MobileNetV2\n",
        "\n",
        "**{get_text('detected_diseases', lang)}:**\n",
        "- {get_text('healthy_pods', lang)}\n",
        "- {get_text('black_rot', lang)}\n",
        "- {get_text('pod_borer_pest', lang)}\n",
        "\"\"\")\n",
        "\n",
        "model1, model2, model3, model_resnet, base_model_resnet = load_models()\n",
        "\n",
        "if app_mode.startswith(\"🔍\"):\n",
        "    st.title(\"🍫 \" + get_text('main_title', lang))\n",
        "    st.markdown(get_text('subtitle', lang))\n",
        "\n",
        "    origen_img = st.radio(get_text('select_image_source', lang), (get_text('upload_from_computer', lang), get_text('select_from_github', lang)))\n",
        "    image = None\n",
        "\n",
        "    if origen_img == get_text('upload_from_computer', lang):\n",
        "        uploaded_file_img = st.file_uploader(get_text('upload_image', lang), type=[\"jpg\", \"jpeg\", \"png\"], key=\"diagnostico_img\")\n",
        "        if uploaded_file_img:\n",
        "            image = Image.open(uploaded_file_img).convert(\"RGB\")\n",
        "    elif origen_img == get_text('select_from_github', lang):\n",
        "        st.markdown(get_text('searching_images', lang))\n",
        "        imagenes_disponibles = listar_imagenes_github(GITHUB_USER, GITHUB_REPO, GITHUB_IMG_FOLDER)\n",
        "        imagenes_disponibles = [f for f in imagenes_disponibles if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
        "        if imagenes_disponibles:\n",
        "            imagen_elegida = st.selectbox(get_text('choose_image', lang), imagenes_disponibles, key=\"img_github_select\")\n",
        "            if st.button(get_text('load_selected_image', lang)):\n",
        "                url_img = get_github_image_url(GITHUB_USER, GITHUB_REPO, GITHUB_IMG_FOLDER, imagen_elegida)\n",
        "                image_github = cargar_imagen_desde_github(url_img)\n",
        "                if image_github:\n",
        "                    image = image_github\n",
        "                    st.success(f\"{get_text('image_loaded_success', lang)} '{imagen_elegida}'.\")\n",
        "                else:\n",
        "                    st.error(get_text('error_loading_image', lang))\n",
        "        else:\n",
        "            st.warning(get_text('no_images_found', lang))\n",
        "\n",
        "    if image:\n",
        "        st.image(image, caption=get_text('image_loaded', lang), use_container_width=True)\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"## \" + get_text('automatic_diagnosis', lang))\n",
        "        with st.spinner(get_text('processing', lang)):\n",
        "            img_pre = preprocess_image(image, (128, 128))\n",
        "            pred1 = model1.predict(img_pre)[0]\n",
        "            pred2 = model2.predict(img_pre)[0]\n",
        "            pred3 = model3.predict(img_pre)[0]\n",
        "            predictions = [pred1, pred2, pred3]\n",
        "\n",
        "            consensus = int(np.round(np.mean([np.argmax(p) for p in predictions])))\n",
        "            disease = DISEASE_INFO[consensus]\n",
        "\n",
        "            resnet_input = preprocess_image(image, (IMG_HEIGHT_GRADCAM, IMG_WIDTH_GRADCAM))\n",
        "            resnet_preds = model_resnet.predict(resnet_input)[0]\n",
        "            resnet_pred_class = int(np.argmax(resnet_preds))\n",
        "            heatmap = make_gradcam_heatmap(resnet_input, base_model_resnet, \"conv5_block3_out\", pred_index=resnet_pred_class)\n",
        "            gradcam_img = superimpose_heatmap(image, heatmap)\n",
        "            buffered_gradcam = BytesIO()\n",
        "            gradcam_img.save(buffered_gradcam, format=\"PNG\")\n",
        "            st.session_state.gradcam_img_base64 = base64.b64encode(buffered_gradcam.getvalue()).decode()\n",
        "\n",
        "            st.subheader(f\"{get_text('ai_diagnosis', lang)}: **{disease['name']}**\")\n",
        "            st.markdown(f\"**{get_text('description', lang)}:** {disease['desc']}\")\n",
        "            st.markdown(f\"**{get_text('severity', lang)}:** {disease['severity']}\")\n",
        "\n",
        "            st.image(gradcam_img, caption=get_text('gradcam_caption', lang), use_container_width=False, width=420)\n",
        "            st.markdown(\"> **\" + get_text('gradcam_description', lang) + \"**\")\n",
        "\n",
        "            st.markdown(\"### \" + get_text('model_confidence', lang))\n",
        "            fig_conf = create_confidence_chart(predictions, MODEL_NAMES)\n",
        "            st.plotly_chart(fig_conf, use_container_width=True)\n",
        "\n",
        "            st.markdown(\"### \" + get_text('treatment_prevention', lang))\n",
        "            st.markdown(f\"**{get_text('recommended_treatment', lang)}:**\\n{disease['treatment']}\")\n",
        "            st.markdown(f\"**{get_text('prevention', lang)}:** {disease['prevention']}\")\n",
        "\n",
        "            features = analyze_image_features(image)\n",
        "            st.markdown(\"### \" + get_text('image_features', lang))\n",
        "            st.write({\n",
        "                get_text('avg_brightness', lang): f\"{features['brightness']:.2f}\",\n",
        "                get_text('texture_variance', lang): f\"{features['texture_variance']:.2f}\",\n",
        "                get_text('contrast', lang): f\"{features['contrast']:.2f}\"\n",
        "            })\n",
        "\n",
        "            html_report = generate_individual_report(image, predictions, features, consensus, lang)\n",
        "            st.markdown(\"## 📄 \" + get_text('download_report', lang))\n",
        "            generate_html_download(html_report, lang=lang)\n",
        "            if PDFKIT_AVAILABLE:\n",
        "                generate_pdf_report(html_report, lang=lang)\n",
        "\n",
        "elif app_mode.startswith(\"📚\"):\n",
        "    st.title(\"📚 \" + get_text('disease_guide_title', lang))\n",
        "    tabs = st.tabs([f\"{DISEASE_INFO[i]['name']}\" for i in range(3)])\n",
        "    for i, tab in enumerate(tabs):\n",
        "        with tab:\n",
        "            disease = DISEASE_INFO[i]\n",
        "            col1, col2 = st.columns([1, 1])\n",
        "            with col1:\n",
        "                st.markdown(f\"### {disease['name']}\")\n",
        "                img_path = f\"{i}.jpg\"\n",
        "                if os.path.exists(img_path):\n",
        "                    st.image(img_path, caption=f\"{get_text('example_image', lang)} {disease['name']}\", use_container_width=True)\n",
        "                else:\n",
        "                    st.info(f\"💡 {get_text('example_not_available', lang)} {disease['name']}\")\n",
        "                st.markdown(f\"#### 📊 {get_text('general_info', lang)}\")\n",
        "                st.metric(get_text('severity', lang), disease['severity'])\n",
        "            with col2:\n",
        "                st.markdown(f\"#### 📝 {get_text('description', lang)}\")\n",
        "                st.write(disease['desc'])\n",
        "                st.markdown(f\"#### 🔍 {get_text('symptoms', lang)}\")\n",
        "                st.write(disease['symptoms'])\n",
        "                st.markdown(f\"#### 🛡️ {get_text('preventive_measures', lang)}\")\n",
        "                st.write(disease['prevention'])\n",
        "            st.markdown(f\"#### 💊 {get_text('recommended_treatment', lang)}\")\n",
        "            st.markdown(f\"\"\"\n",
        "            <div class=\"card {disease['class']}\">\n",
        "                <pre style=\"white-space: pre-wrap; font-family: inherit; margin: 0;\">{disease['treatment']}</pre>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "elif app_mode.startswith(\"📊\"):\n",
        "    st.title(\"📊 \" + get_text('comparative_analysis_title', lang))\n",
        "    tab1, tab2 = st.tabs([\"🔬 \" + get_text('performance_analysis', lang), \"📄 \" + get_text('generate_report', lang)])\n",
        "\n",
        "    with tab1:\n",
        "        st.markdown(\"### \" + get_text('model_evaluation', lang))\n",
        "        st.info(\"\\n\".join([\"**\" + get_text('instructions', lang) + \":**\"] + [f\"{i+1}. {s}\" for i, s in enumerate(get_text('detailed_instructions', lang))]))\n",
        "\n",
        "        with st.expander(\"📥 \" + get_text('download_example', lang)):\n",
        "            example_data = pd.DataFrame({\n",
        "                \"y_true\": [0,1,2,0,1,2,0,1,2,0,1,2,0,1,2] * 10,\n",
        "                \"y_pred1\": [0,1,2,0,1,2,0,2,1,0,1,2,0,1,2] * 10,\n",
        "                \"y_pred2\": [0,1,2,0,2,2,0,1,1,0,1,2,0,1,2] * 10,\n",
        "                \"y_pred3\": [0,1,2,1,1,2,0,1,2,0,1,2,0,1,2] * 10,\n",
        "            })\n",
        "            st.dataframe(example_data.head(10), use_container_width=True)\n",
        "            csv_example = example_data.to_csv(index=False).encode()\n",
        "            st.download_button(\n",
        "                \"📥 \" + get_text('download_example', lang),\n",
        "                csv_example,\n",
        "                \"ejemplo_evaluacion_modelos.csv\",\n",
        "                \"text/csv\"\n",
        "            )\n",
        "\n",
        "        origen_csv = st.radio(get_text('select_csv_source', lang), (get_text('upload_from_computer', lang), get_text('select_from_github', lang)))\n",
        "        csv_file = None\n",
        "\n",
        "        if origen_csv == get_text('upload_from_computer', lang):\n",
        "            csv_file = st.file_uploader(\n",
        "                \"📁 \" + get_text('load_csv', lang),\n",
        "                type=\"csv\",\n",
        "                key=\"comparison_csv\"\n",
        "            )\n",
        "        else:\n",
        "            st.markdown(get_text('searching_csv', lang))\n",
        "            csvs_disponibles = listar_archivos_github(GITHUB_USER, GITHUB_REPO, GITHUB_IMG_FOLDER, [\".csv\"])\n",
        "            if csvs_disponibles:\n",
        "                csv_elegido = st.selectbox(get_text('choose_csv', lang), csvs_disponibles)\n",
        "                if st.button(get_text('load_selected_csv', lang)):\n",
        "                    url_csv = get_github_image_url(GITHUB_USER, GITHUB_REPO, GITHUB_IMG_FOLDER, csv_elegido)\n",
        "                    response = requests.get(url_csv)\n",
        "                    if response.status_code == 200:\n",
        "                        csv_file = io.BytesIO(response.content)\n",
        "                        st.success(f\"{get_text('file_loaded', lang)} '{csv_elegido}'.\")\n",
        "                    else:\n",
        "                        st.error(get_text('error_loading_csv', lang))\n",
        "            else:\n",
        "                st.warning(get_text('no_csv_found', lang))\n",
        "\n",
        "        if csv_file is not None:\n",
        "            df = pd.read_csv(csv_file)\n",
        "            df.columns = df.columns.str.strip().str.lower()\n",
        "            required_cols = ['y_true', 'y_pred1', 'y_pred2', 'y_pred3']\n",
        "            if not all(col in df.columns for col in required_cols):\n",
        "                st.error(f\"❌ {get_text('error_loading_csv', lang)}: {required_cols}\")\n",
        "                st.write(f\"Columnas encontradas: {list(df.columns)}\")\n",
        "                st.stop()\n",
        "            y_true = df['y_true']\n",
        "            y_pred1 = df['y_pred1']\n",
        "            y_pred2 = df['y_pred2']\n",
        "            y_pred3 = df['y_pred3']\n",
        "            predictions = [y_pred1, y_pred2, y_pred3]\n",
        "            st.session_state.eval_predictions = predictions\n",
        "            st.session_state.eval_y_true = y_true\n",
        "            st.success(f\"✅ {get_text('file_loaded', lang)}. {len(df)} {get_text('samples_found', lang)}.\")\n",
        "\n",
        "            metrics = []\n",
        "            confusion_figs = []\n",
        "            for i, (y_pred, name) in enumerate(zip(predictions, MODEL_NAMES)):\n",
        "                advanced_metrics = calculate_advanced_metrics(y_true, y_pred)\n",
        "                metrics.append(advanced_metrics)\n",
        "                fig = plot_confusion_matrix_mpl(y_true, y_pred, CLASSES, f\"{get_text('model', lang)} - {name}\")\n",
        "                img_base64 = fig_to_base64(fig)\n",
        "                confusion_figs.append(img_base64)\n",
        "            metric_df = pd.DataFrame({\n",
        "                get_text('model', lang): MODEL_NAMES,\n",
        "                get_text('precision', lang): [m['accuracy'] for m in metrics],\n",
        "                get_text('recall', lang): [m['report']['macro avg']['recall'] for m in metrics],\n",
        "                get_text('f1_score', lang): [m['report']['macro avg']['f1-score'] for m in metrics],\n",
        "                get_text('mcc', lang): [m['mcc'] for m in metrics],\n",
        "                get_text('avg_specificity', lang): [np.mean(m['specificity']) for m in metrics]\n",
        "            })\n",
        "            styled_df = metric_df.style.highlight_max(axis=0)\n",
        "            st.dataframe(styled_df, use_container_width=True)\n",
        "            with st.expander(\"🛈 ¿Qué significa cada métrica?\"):\n",
        "                for k, v in METRIC_DESCRIPTIONS.items():\n",
        "                    st.markdown(f\"- **{k}:** {v}\")\n",
        "            best_idx = int(np.argmax(metric_df[get_text('mcc', lang)]))\n",
        "            st.success(f\"⭐ {get_text('best_model', lang)}: **{MODEL_NAMES[best_idx]}** ({get_text('mcc', lang)}: {metric_df[get_text('mcc', lang)][best_idx]:.4f})\")\n",
        "            st.markdown(\"#### 📊 \" + get_text('statistical_analysis', lang))\n",
        "            for i in range(len(MODEL_NAMES)):\n",
        "                for j in range(i+1, len(MODEL_NAMES)):\n",
        "                    stat, pval = mcnemar_test(y_true, predictions[i], predictions[j])\n",
        "                    signo = \"✅ \" + get_text('significant', lang) if pval < 0.05 else \"❌ \" + get_text('not_significant', lang)\n",
        "                    st.write(f\"{MODEL_NAMES[i]} vs {MODEL_NAMES[j]}: Estadístico = {stat:.3f}, p-valor = {pval:.4f} {signo}\")\n",
        "\n",
        "            st.session_state.eval_metrics = metrics\n",
        "            st.session_state.eval_confusion_figs = confusion_figs\n",
        "            st.session_state.eval_model_names = MODEL_NAMES\n",
        "\n",
        "    with tab2:\n",
        "        st.markdown(\"### 📄 \" + get_text('generate_comparative_report', lang))\n",
        "        if ('eval_metrics' not in st.session_state or\n",
        "            'eval_predictions' not in st.session_state or\n",
        "            'eval_y_true' not in st.session_state):\n",
        "            st.warning(\"⚠️ \" + get_text('analysis_first', lang))\n",
        "        else:\n",
        "            st.info(get_text('report_includes', lang))\n",
        "            if st.button(\"🔄 \" + get_text('generate_comparative_report', lang), type=\"primary\"):\n",
        "                with st.spinner(get_text('generating_report', lang)):\n",
        "                    try:\n",
        "                        metrics = st.session_state.eval_metrics\n",
        "                        confusion_figs = st.session_state.eval_confusion_figs\n",
        "                        html_report = generate_comparative_report(\n",
        "                            metrics,\n",
        "                            confusion_figs,\n",
        "                            MODEL_NAMES,\n",
        "                            st.session_state.eval_y_true,\n",
        "                            st.session_state.eval_predictions,\n",
        "                            lang\n",
        "                        )\n",
        "                        if PDFKIT_AVAILABLE:\n",
        "                            pdf_bytes = pdfkit.from_string(html_report, False)\n",
        "                            st.download_button(\n",
        "                                label=f\"📄 {get_text('download_pdf', lang)}\",\n",
        "                                data=pdf_bytes,\n",
        "                                file_name=f\"reporte_comparativo_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf\",\n",
        "                                mime=\"application/pdf\"\n",
        "                            )\n",
        "                            st.success(\"✅ \" + get_text('report_generated', lang))\n",
        "                        else:\n",
        "                            generate_html_download(html_report, filename_prefix=\"reporte_comparativo\", lang=lang)\n",
        "                            st.info(get_text('pdfkit_not_available', lang))\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Error generando reporte: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVxLXhWb5i_Y",
        "outputId": "6c6a464a-e011-4275-ac49-48abd2fd0f00"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVqAciV7R7py",
        "outputId": "b7ac0e42-717c-4d07-f103-3ee222722f08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0Kyour url is: https://plain-corners-count.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}